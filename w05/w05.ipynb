{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a: \n",
    "__Q:__ In the perceptron below, what will the output be when the input is (0, 0)? What about inputs (0, 1), (1, 1) and (1, 0)? What if we change the bias weight to -0.5? <br>\n",
    "\n",
    "__A:__<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1]\n",
      " [0 1 0 1]\n",
      " [1 1 1 1]]\n",
      "\n",
      "  [-1.5 -0.5 -0.5  0.5]\n",
      "\n",
      "  [-0.5  0.5  0.5  1.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = np.array(((0,0, 1), (0, 1, 1), (1,0, 1), (1,1,1))).T\n",
    "print(inputs)\n",
    "weights = np.array((1, 1, -1.5))\n",
    "total  = np.dot(weights,inputs)\n",
    "print('\\n ',total)\n",
    "\n",
    "weights = np.array((1, 1, -0.5))\n",
    "total  = np.dot(weights,inputs)\n",
    "print('\\n ',total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output = 1 if element larger than 1.\n",
    "\n",
    "# 1b\n",
    "__Q:__ Starting with random weights, how do you proceed in order to train the perceptron above to perform any given\n",
    "binary operation? Explain. <br>\n",
    "\n",
    "__A:__ We have $$Error = target - output.$$\n",
    "The weights are then adjusted according to $$\\Delta \\omega_i = \\eta*Error*x_i $$\n",
    "\n",
    "# 1c\n",
    "__Q:__ Implement the perceptron, and train it to perform the logical functions NOT (use only one of the inputs), NAND,\n",
    "and NOR. What happens when you try to train it do the XOR function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerPerceptron:\n",
    "    \"\"\" \n",
    "    Single output node\n",
    "    Inputs argument must be a matrix with one input vector per column\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inputs, maxIterations, trueFunction, tolerance, learningRate):\n",
    "        self.inputs = inputs\n",
    "        self.numberOfInputs = np.shape(self.inputs)[1]\n",
    "        self.maxIterations = maxIterations\n",
    "        self.trueFunction = trueFunction\n",
    "        self.tolerance = tolerance\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "    def runNetwork(self):\n",
    "        self.initializeWeights()\n",
    "        self.iterationNumber = 0\n",
    "        numberOfAdjustmentsDuringIteration = 1\n",
    "        while (self.iterationNumber < self.maxIterations and numberOfAdjustmentsDuringIteration != 0):\n",
    "            self.iterationNumber += 1\n",
    "            numberOfAdjustmentsDuringIteration = 0\n",
    "            \n",
    "            for inputNumber in range(self.numberOfInputs):\n",
    "                self.inputVector = self.inputs[:,inputNumber]\n",
    "                self.weighInput()\n",
    "                self.thresholding()\n",
    "                self.calculateTarget()\n",
    "                self.calculateError()\n",
    "\n",
    "                if abs(self.error) > self.tolerance:\n",
    "                    numberOfAdjustmentsDuringIteration +=1\n",
    "                    self.adjustWeights()\n",
    "       \n",
    "        self.printFinalWeights()\n",
    "                    \n",
    "        \n",
    "    def initializeWeights(self):\n",
    "        np.random.seed(1)\n",
    "        numberOfWeights = np.shape(self.inputs)[0]\n",
    "        self.weights = np.random.uniform(-.25, .25, (1,numberOfWeights))\n",
    "        \n",
    "        \n",
    "    def weighInput(self):\n",
    "        self.weightedInput = np.asscalar(np.dot(self.weights, self.inputVector))\n",
    "        \n",
    "    def thresholding(self):\n",
    "        if self.weightedInput > 0: \n",
    "            self.output = 1\n",
    "        else:\n",
    "            self.output = 0\n",
    "            \n",
    "    def calculateTarget(self):\n",
    "        self.target = self.trueFunction(self.inputVector[1:])\n",
    "        \n",
    "    def calculateError(self):\n",
    "        self.error =  self.target - self.output\n",
    "    \n",
    "    def adjustWeights(self):\n",
    "        deltaWeights = self.learningRate*self.error*self.inputVector\n",
    "        self.weights += deltaWeights\n",
    "        \n",
    "    def printFinalWeights(self):\n",
    "        print('\\n Weights: \\n', self.weights, '\\n Number of iterations: ', self.iterationNumber)\n",
    "        \n",
    "    def predict(self, newInput):\n",
    "        self.inputVector = newInput\n",
    "        self.weighInput()\n",
    "        self.thresholding()\n",
    "        print('Input: ', newInput, 'Predicted output: ', self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:    \n",
    "    \"\"\" Based on input vetors and a function, the class SingleLayerPerceptron is called upon and run \"\"\"\n",
    "    def __init__(self, function, inputs):\n",
    "        self.function, self.inputs = function, inputs\n",
    "        #print('inputs iun problem', inputs)\n",
    "\n",
    "    def solve(self):\n",
    "        print(\"\\n Function: \", self.function.__name__)\n",
    "        maxIterations = 1000\n",
    "        tolerance = 1e-12\n",
    "        learningRate = 1e-1\n",
    "        \n",
    "        tst= SingleLayerPerceptron(self.inputs, maxIterations, self.function, tolerance, learningRate)\n",
    "        tst.runNetwork()\n",
    "        \n",
    "        for i in range(np.shape(self.inputs)[1]):\n",
    "            tst.predict(self.inputs[:,i])\n",
    "         \n",
    "        #testArray = np.array((-1, 0.2, 1.5))\n",
    "        #tst.predict(testArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Function:  nand\n",
      "\n",
      " Weights: \n",
      " [[-0.341489   -0.28983775 -0.14994281]] \n",
      " Number of iterations:  9\n",
      "Input:  [-1  0  0] Predicted output:  1\n",
      "Input:  [-1  0  1] Predicted output:  1\n",
      "Input:  [-1  1  0] Predicted output:  1\n",
      "Input:  [-1  1  1] Predicted output:  0\n",
      "\n",
      " Function:  nor\n",
      "\n",
      " Weights: \n",
      " [[-0.041489   -0.08983775 -0.24994281]] \n",
      " Number of iterations:  4\n",
      "Input:  [-1  0  0] Predicted output:  1\n",
      "Input:  [-1  0  1] Predicted output:  0\n",
      "Input:  [-1  1  0] Predicted output:  0\n",
      "Input:  [-1  1  1] Predicted output:  0\n",
      "\n",
      " Function:  notFunction\n",
      "\n",
      " Weights: \n",
      " [[-0.041489   -0.08983775]] \n",
      " Number of iterations:  4\n",
      "Input:  [-1  0] Predicted output:  1\n",
      "Input:  [-1  1] Predicted output:  0\n",
      "\n",
      " Function:  xor\n",
      "\n",
      " Weights: \n",
      " [[-0.041489   -0.08983775 -0.14994281]] \n",
      " Number of iterations:  1000\n",
      "Input:  [-1  0  0] Predicted output:  1\n",
      "Input:  [-1  0  1] Predicted output:  0\n",
      "Input:  [-1  1  0] Predicted output:  0\n",
      "Input:  [-1  1  1] Predicted output:  0\n",
      "\n",
      " NAND TRUE\n",
      "Input:  [0 0] True : 1\n",
      "Input:  [0 1] True : 0\n",
      "Input:  [1 0] True : 0\n",
      "Input:  [1 1] True : 0\n"
     ]
    }
   ],
   "source": [
    "# The exercise examples\n",
    "inputs = np.array(((-1,0, 0), (-1, 0, 1), (-1,1, 0), (-1,1,1))).T\n",
    "inputNot = np.array(((-1,0), (-1,1))).T\n",
    "\n",
    "def nand(array):\n",
    "    if (array[0] == 1 and array[1] == 1):\n",
    "        output  = 0\n",
    "    else:\n",
    "        output = 1\n",
    "    return output\n",
    "\n",
    "def nor(array):\n",
    "    if (array[0] == 0 and array[1] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def notFunction(scalar):\n",
    "    if scalar == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def xor(array):\n",
    "    if (array[0] == 0 and array[1] == 0):\n",
    "        output = 0\n",
    "    elif (array[0] == 0 and array[1] == 1):\n",
    "        output = 1\n",
    "    elif (array[0] == 1 and array[1] == 0):\n",
    "        output = 1\n",
    "    elif (array[0] == 1 and array[1] == 1):\n",
    "        output = 0\n",
    "    return output\n",
    "    \n",
    "\n",
    "inputList = inputs, inputs, inputNot, inputs\n",
    "functionList = nand, nor, notFunction, xor\n",
    "\n",
    "for inputNumber, functionNumber in zip(inputList, functionList):\n",
    "    #print('inputNumber', inputNumber)\n",
    "    p1 = Problem(functionNumber, inputNumber)\n",
    "    p1.solve()\n",
    "\n",
    "print('\\n NAND TRUE')\n",
    "for i in range(4):\n",
    "    print('Input: ', inputs[1:,i], 'True :', nor(inputs[1:,i],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR does not have a converging solution, the other functions is correctly approximated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "__Q:__ The figure below shows a multilayer perceptron that constructs the XOR function. How would you rewrite it to\n",
    "construct the binary equivalence function (i.e. the output is above threshold when both inputs are either 0 or\n",
    "1)? Can you construct it so that it will detect equivalence for any combination of integer inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1.5\n",
      "0.5\n",
      "0.5 -0.5\n"
     ]
    }
   ],
   "source": [
    "def multiLayerForward(i1, i2, w01=-1.5, w02=-.5, w11=1, w12=1, w21=1, w22=1, b=1, v0=-.5, v1=-1, v2=1):\n",
    "    h1 = w01*b+w11*i1+w21*i2\n",
    "    print(h1)\n",
    "    h2 = w02*b+w12*i1+w22*i2\n",
    "    print(h2)\n",
    "    out = v0*b + v1*h1 + v2*h2\n",
    "    outputNew = -v0*b - v1*h1 - v2*h2\n",
    "    print(out)\n",
    "    return out, outputNew\n",
    "\n",
    "i1 = 1\n",
    "i2 = 1\n",
    "\n",
    "out1, out2 = multiLayerForward(i1=i1, i2=i2)#, w01=-1.5, w02=-.5, w11=1, w12=1, w21=1, w22=1, b=1, v0=-.5, v1=-1, v2=1)\n",
    "print(out1, out2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> I am not able to make the network from the drawin work. It always gives output 0.5. <mark> <br>\n",
    "    \n",
    "Given tha the XOR-function works, we can construct a function that works in the opposite way of the XOR-function by changing sign of all the output layer weights. <br>\n",
    "\n",
    "Now to the rewrite so that the network holds for any any number interger numbers. I would scale the first layer weights by the largest input. This would make the weight values become at the same order as the priginal network, with max weight equal to one. <mark> ?? <mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def multiLayerForwardMarsland(i1, i2, w01=-.5, w02=-1., w11=1, w12=1, w21=1, w22=1, b=-11, v0=-.5, v1=1, v2=-1):\n",
    "    h1 = w01*b+w11*i1+w21*i2\n",
    "    #print(h1)\n",
    "    h2 = w02*b+w12*i1+w22*i2\n",
    "    #print(h2)\n",
    "    out = v0*b + v1*h1 + v2*h2\n",
    "    outputNew = -v0*b - v1*h1 - v2*h2\n",
    "    #print(out)\n",
    "    return out, outputNew\n",
    "\n",
    "i1 = 0\n",
    "i2 = 1\n",
    "\n",
    "out1, out2 = multiLayerForwardMarsland(i1=i1, i2=i2)#, w01=-1.5, w02=-.5, w11=1, w12=1, w21=1, w22=1, b=1, v0=-.5, v1=-1, v2=1)\n",
    "print(out1, out2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
