{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a: \n",
    "__Q:__ In the perceptron below, what will the output be when the input is (0, 0)? What about inputs (0, 1), (1, 1) and (1, 0)? What if we change the bias weight to -0.5? <br>\n",
    "\n",
    "__A:__<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1]\n",
      " [0 1 0 1]\n",
      " [1 1 1 1]]\n",
      "\n",
      "  [-1.5 -0.5 -0.5  0.5]\n",
      "\n",
      "  [-0.5  0.5  0.5  1.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = np.array(((0,0, 1), (0, 1, 1), (1,0, 1), (1,1,1))).T\n",
    "print(inputs)\n",
    "weights = np.array((1, 1, -1.5))\n",
    "total  = np.dot(weights,inputs)\n",
    "print('\\n ',total)\n",
    "\n",
    "weights = np.array((1, 1, -0.5))\n",
    "total  = np.dot(weights,inputs)\n",
    "print('\\n ',total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output = 1 if element larger than 1.\n",
    "\n",
    "# 1b\n",
    "__Q:__ Starting with random weights, how do you proceed in order to train the perceptron above to perform any given\n",
    "binary operation? Explain. <br>\n",
    "\n",
    "__A:__ We have $$Error = target - output.$$\n",
    "The weights are then adjusted according to $$\\Delta \\omega_i = \\eta*Error*x_i $$\n",
    "\n",
    "# 1c\n",
    "__Q:__ Implement the perceptron, and train it to perform the logical functions NOT (use only one of the inputs), NAND,\n",
    "and NOR. What happens when you try to train it do the XOR function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerPerceptron:\n",
    "    \"\"\" \n",
    "    Single output node\n",
    "    Inputs argument must be a matrix with one input vector per column\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inputs, maxIterations, trueFunction, tolerance, learningRate):\n",
    "        self.inputs = inputs\n",
    "        self.numberOfInputs = np.shape(self.inputs)[1]\n",
    "        self.maxIterations = maxIterations\n",
    "        self.trueFunction = trueFunction\n",
    "        self.tolerance = tolerance\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "    def runNetwork(self):\n",
    "        self.initializeWeights()\n",
    "        self.iterationNumber = 0\n",
    "        numberOfAdjustmentsDuringIteration = 1\n",
    "        while (self.iterationNumber < self.maxIterations and numberOfAdjustmentsDuringIteration != 0):\n",
    "            self.iterationNumber += 1\n",
    "            numberOfAdjustmentsDuringIteration = 0\n",
    "            \n",
    "            for inputNumber in range(self.numberOfInputs):\n",
    "                self.inputVector = self.inputs[:,inputNumber]\n",
    "                self.weighInput()\n",
    "                self.thresholding()\n",
    "                self.calculateTarget()\n",
    "                self.calculateError()\n",
    "\n",
    "                if abs(self.error) > self.tolerance:\n",
    "                    numberOfAdjustmentsDuringIteration +=1\n",
    "                    self.adjustWeights()\n",
    "       \n",
    "        self.printFinalWeights()\n",
    "                    \n",
    "        \n",
    "    def initializeWeights(self):\n",
    "        np.random.seed(1)\n",
    "        numberOfWeights = np.shape(self.inputs)[0]\n",
    "        self.weights = np.random.uniform(-.25, .25, (1,numberOfWeights))\n",
    "        \n",
    "        \n",
    "    def weighInput(self):\n",
    "        self.weightedInput = np.asscalar(np.dot(self.weights, self.inputVector))\n",
    "        \n",
    "    def thresholding(self):\n",
    "        if self.weightedInput > 0: \n",
    "            self.output = 1\n",
    "        else:\n",
    "            self.output = 0\n",
    "            \n",
    "    def calculateTarget(self):\n",
    "        self.target = self.trueFunction(self.inputVector[1:])\n",
    "        \n",
    "    def calculateError(self):\n",
    "        self.error =  self.target - self.output\n",
    "    \n",
    "    def adjustWeights(self):\n",
    "        deltaWeights = self.learningRate*self.error*self.inputVector\n",
    "        self.weights += deltaWeights\n",
    "        \n",
    "    def printFinalWeights(self):\n",
    "        print('\\n Weights: \\n', self.weights, '\\n Number of iterations: ', self.iterationNumber)\n",
    "        \n",
    "    def predict(self, newInput):\n",
    "        self.inputVector = newInput\n",
    "        self.weighInput()\n",
    "        self.thresholding()\n",
    "        print('Input: ', newInput, 'Predicted output: ', self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:    \n",
    "    \"\"\" Based on input vetors and a function, the class SingleLayerPerceptron is called upon and run \"\"\"\n",
    "    def __init__(self, function, inputs):\n",
    "        self.function, self.inputs = function, inputs\n",
    "        #print('inputs iun problem', inputs)\n",
    "\n",
    "    def solve(self):\n",
    "        print(\"\\n Function: \", self.function.__name__)\n",
    "        maxIterations = 1000\n",
    "        tolerance = 1e-12\n",
    "        learningRate = 1e-1\n",
    "        \n",
    "        tst= SingleLayerPerceptron(self.inputs, maxIterations, self.function, tolerance, learningRate)\n",
    "        tst.runNetwork()\n",
    "        \n",
    "        for i in range(np.shape(self.inputs)[1]):\n",
    "            tst.predict(self.inputs[:,i])\n",
    "         \n",
    "        #testArray = np.array((-1, 0.2, 1.5))\n",
    "        #tst.predict(testArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Function:  nand\n",
      "\n",
      " Weights: \n",
      " [[-0.341489   -0.28983775 -0.14994281]] \n",
      " Number of iterations:  9\n",
      "Input:  [-1  0  0] Predicted output:  1\n",
      "Input:  [-1  0  1] Predicted output:  1\n",
      "Input:  [-1  1  0] Predicted output:  1\n",
      "Input:  [-1  1  1] Predicted output:  0\n",
      "\n",
      " Function:  nor\n",
      "\n",
      " Weights: \n",
      " [[-0.041489   -0.08983775 -0.24994281]] \n",
      " Number of iterations:  4\n",
      "Input:  [-1  0  0] Predicted output:  1\n",
      "Input:  [-1  0  1] Predicted output:  0\n",
      "Input:  [-1  1  0] Predicted output:  0\n",
      "Input:  [-1  1  1] Predicted output:  0\n",
      "\n",
      " Function:  notFunction\n",
      "\n",
      " Weights: \n",
      " [[-0.041489   -0.08983775]] \n",
      " Number of iterations:  4\n",
      "Input:  [-1  0] Predicted output:  1\n",
      "Input:  [-1  1] Predicted output:  0\n",
      "\n",
      " Function:  xor\n",
      "\n",
      " Weights: \n",
      " [[-0.041489   -0.08983775 -0.14994281]] \n",
      " Number of iterations:  1000\n",
      "Input:  [-1  0  0] Predicted output:  1\n",
      "Input:  [-1  0  1] Predicted output:  0\n",
      "Input:  [-1  1  0] Predicted output:  0\n",
      "Input:  [-1  1  1] Predicted output:  0\n",
      "\n",
      " NAND TRUE\n",
      "Input:  [0 0] True : 1\n",
      "Input:  [0 1] True : 0\n",
      "Input:  [1 0] True : 0\n",
      "Input:  [1 1] True : 0\n"
     ]
    }
   ],
   "source": [
    "# The exercise examples\n",
    "inputs = np.array(((-1,0, 0), (-1, 0, 1), (-1,1, 0), (-1,1,1))).T\n",
    "inputNot = np.array(((-1,0), (-1,1))).T\n",
    "\n",
    "def nand(array):\n",
    "    if (array[0] == 1 and array[1] == 1):\n",
    "        output  = 0\n",
    "    else:\n",
    "        output = 1\n",
    "    return output\n",
    "\n",
    "def nor(array):\n",
    "    if (array[0] == 0 and array[1] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def notFunction(scalar):\n",
    "    if scalar == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def xor(array):\n",
    "    if (array[0] == 0 and array[1] == 0):\n",
    "        output = 0\n",
    "    elif (array[0] == 0 and array[1] == 1):\n",
    "        output = 1\n",
    "    elif (array[0] == 1 and array[1] == 0):\n",
    "        output = 1\n",
    "    elif (array[0] == 1 and array[1] == 1):\n",
    "        output = 0\n",
    "    return output\n",
    "    \n",
    "\n",
    "inputList = inputs, inputs, inputNot, inputs\n",
    "functionList = nand, nor, notFunction, xor\n",
    "\n",
    "for inputNumber, functionNumber in zip(inputList, functionList):\n",
    "    #print('inputNumber', inputNumber)\n",
    "    p1 = Problem(functionNumber, inputNumber)\n",
    "    p1.solve()\n",
    "\n",
    "print('\\n NAND TRUE')\n",
    "for i in range(4):\n",
    "    print('Input: ', inputs[1:,i], 'True :', nor(inputs[1:,i],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR does not have a converging solution, the other functions is correctly approximated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
