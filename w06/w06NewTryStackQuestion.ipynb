{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  500 |Error|:  [0.26604698]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NN:\n",
    "    \"\"\" XOR function test. 1 hidden layer with 2 hidden nodes in addition to bias node.\"\"\"\n",
    "    def __init__(self, nodeNumbers, learningRate, targetMatrix, inputMatrix, errorTolerance, \\\n",
    "                 maxIterations):\n",
    "        self.nodeNumbers,  self.learningRate, self.targetMatrix, \\\n",
    "        self.inputMatrix, self.errorTolerance, self.maxIterations = \\\n",
    "        nodeNumbers, learningRate, targetMatrix, inputMatrix, errorTolerance, \\\n",
    "                 maxIterations\n",
    "        \n",
    "        self.numberOfInputs = np.shape(self.inputMatrix)[1]\n",
    "        \n",
    "        self.weightMatrices = []\n",
    "        for nodeNumber in range(len(nodeNumbers[1:])):\n",
    "            self.weightMatrices.append(np.random.random_sample((nodeNumbers[nodeNumber+1], \\\n",
    "                                                        nodeNumbers[nodeNumber]+1)).T - .5)  \n",
    "        \n",
    "    def activationFunction(self, x):\n",
    "        return 1./(1+np.exp(-x))\n",
    "\n",
    "    def derivative(self, weightedInputs):\n",
    "        return self.activationFunction(weightedInputs)*(1 - self.activationFunction(weightedInputs))        \n",
    "        \n",
    "    def run(self):\n",
    "        self.iterationNumber = 0\n",
    "        numberOfAdjustmentsDuringIteration = 1\n",
    "        \n",
    "        while (self.iterationNumber < self.maxIterations and numberOfAdjustmentsDuringIteration != 0):\n",
    "            self.iterationNumber += 1\n",
    "            numberOfAdjustmentsDuringIteration = 0\n",
    "\n",
    "            for inputNumber in range(self.numberOfInputs):\n",
    "                self.inputs = self.inputMatrix[:,inputNumber]\n",
    "                self.targets = self.targetMatrix[inputNumber]\n",
    "                self.forward()\n",
    "                self.calculateError()\n",
    "                \n",
    "                if abs(self.error2) > self.errorTolerance:\n",
    "                    numberOfAdjustmentsDuringIteration +=1\n",
    "                    self.backward()\n",
    "        print('Iterations: ', self.iterationNumber, '|Error|: ', self.error2)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.u1 = self.weightMatrices[0].T @ self.inputMatrix.T[0,:]\n",
    "        z1 = self.activationFunction(self.u1)\n",
    "        self.z1 = np.concatenate([[-1], z1])\n",
    "        self.u2 = self.weightMatrices[1].T @ self.z1\n",
    "        self.z2 = self.activationFunction(self.u2)\n",
    "        \n",
    "    def calculateError(self):\n",
    "        self.error2 = (self.targets - self.z2)**2\n",
    "        \n",
    "    def backward(self, inputs=False, targets=False):    \n",
    "        self.delta2 = (self.z2 - self.targets)*self.derivative(self.u2) \n",
    "        \n",
    "        delta11 = self.derivative(self.u1[0])*self.delta2* self.weightMatrices[1][0]\n",
    "        delta12 = self.derivative(self.u1[1])*self.delta2* self.weightMatrices[1][1]\n",
    "        self.delta1 = np.concatenate([delta11, delta12])\n",
    "        \n",
    "        self.weightMatrices[1][0,0] -= self.learningRate*self.delta2*self.z1[0]\n",
    "        self.weightMatrices[1][1,0] -= self.learningRate*self.delta2*self.z1[1]\n",
    "        self.weightMatrices[1][2,0] -= self.learningRate*self.delta2*self.z1[2]\n",
    "        \n",
    "        self.weightMatrices[0][0,0] -= self.learningRate*self.delta1[0]*self.inputs[0]\n",
    "        self.weightMatrices[0][1,0] -= self.learningRate*self.delta1[0]*self.inputs[1]\n",
    "        self.weightMatrices[0][0,1] -= self.learningRate*self.delta1[1]*self.inputs[0]\n",
    "        self.weightMatrices[0][1,1] -= self.learningRate*self.delta1[1]*self.inputs[1]\n",
    "        \n",
    "    def predict(self, newInput):\n",
    "        self.inputs = newInput\n",
    "        self.forward()\n",
    "        print('Input: ', newInput, 'Predicted output: ', self.z2)\n",
    "\n",
    "        \n",
    "nodeNumbers = [2,2,1]\n",
    "activationFunction = activationFunction\n",
    "derivative = differentiateActivationFunction\n",
    "learningRate = 0.3\n",
    "targetMatrix = np.array(((0), (1), (1), (0))).T\n",
    "inputMatrix = np.array(((-1,0, 0), (-1, 0, 1), (-1,1, 0), (-1,1,1))).T\n",
    "\n",
    "errorTolerance = 1e-3\n",
    "maxIterations= 500\n",
    "\n",
    "nn=NN(nodeNumbers, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations)\n",
    "nn.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [-1  0  0] Predicted output:  [0.49987204]\n",
      "Input:  [-1  0  1] Predicted output:  [0.49987204]\n",
      "Input:  [-1  1  0] Predicted output:  [0.49987204]\n",
      "Input:  [-1  1  1] Predicted output:  [0.49987204]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array(((-1,0, 0), (-1, 0, 1), (-1,1, 0), (-1,1,1)))\n",
    "\n",
    "for inp in inputs:\n",
    "    nn.predict(inp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
