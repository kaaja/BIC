{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Last week we used the activation function. Why is this not used with backpropagation?\n",
    "\n",
    "__A:__ The function is not differentiable.\n",
    "\n",
    "# 2 What is the minimum number of hidden neuron layers needed in order to approximate an arbitrary continuous function, and why?\n",
    "\n",
    "__A:__ One hidden layer is the minimum. \"Universal approximation theorem: Any continuous function\n",
    "can be approximated by a neural network with a single\n",
    "hidden layer\", slide 54 https://www.uio.no/studier/emner/matnat/ifi/INF3490/h18/timeplan/slides/lecture6-1pp.pdf\n",
    "\n",
    "\n",
    "Without a hidden layer, it is impossible to approximate non-linear separable problems. The first layer gives lines, and the second layer opens up the dimension to two, so e.g. traingles can be made. Furthermore, a compbination of enough traingles can approximate any shape. See slide 12 https://www.uio.no/studier/emner/matnat/ifi/INF3490/h18/timeplan/slides/lecture6-1pp.pdf\n",
    "\n",
    "<mark> UNCLEAR <br>\n",
    "    \n",
    "    \n",
    "    \n",
    "# 3 Why do we use a validation set? Describe how the three different cross-validation methods presented in the lecture slides work, and what their advantages and disadvantages are.\n",
    "We want the model to generalize well, meaning that it works well on other data than the data the model was estimated on. When fitting the model to the full dataset, the model will typically not fit well for other data. In oredr to create a model that generalizes well, the data is split into a training and a validation set. The model is fit to the training set, and is then evaluated on the validation set. The model performance on the validation set describes how well the model generalizes. <br>\n",
    "\n",
    "Three crossvalidation methods. <br> \n",
    "1) Split into training and validation (and possible test). Works as the previous paragraph. <br>\n",
    "2) K-fold cross-validation. Split into K number of folds. Each fold performs as validation set once, while at the same time the model is fit to the remaining folds. <br>\n",
    "3) Bootstrapping. Draw random observations with replacement and use the rest as validation. Repeat.\n",
    "\n",
    "# 4 Implement the MLP shown below, and train it to correctly perform the XOR function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('nn.weightMatrices',nn.weightMatrices)\\n\\nnn.forward()\\nprint('nn.weightedInputs',nn.weightedInputs)\\nprint('nn.outputs',nn.outputs)\\n\\nnn.calculateErrors()\\nprint('nn.error2',nn.error2)\\n\\nnn.backward()\\nprint('nn.deltaVectors',nn.deltaVectors)\\nprint('weightMatrices', nn.weightMatrices)\\n\\nnn.run()\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "class NN:\n",
    "    \"\"\" 2 layer (1 hidden). Single input combination of 2 intergers. Output 2 integers\"\"\"\n",
    "    \n",
    "    def __init__(self, nodeNumbers, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, \\\n",
    "                 maxIterations, test=False):\n",
    "        self.nodeNumbers, self.activationFunction, self.learningRate, self.targetMatrix, self.inputMatrix, self.errorTolerance,  \\\n",
    "        self.maxIterations, self.test= nodeNumbers, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance,\\\n",
    "        maxIterations, test\n",
    "        \n",
    "        \n",
    "        self.weightMatrices = []\n",
    "        \n",
    "        # If single input\n",
    "        if self.inputMatrix.ndim == 1:\n",
    "            self.inputs = self.inputMatrix.tolist()\n",
    "            self.targets = self.targetMatrix.tolist()\n",
    "            self.targetLength = self.targets\n",
    "        else:\n",
    "            self.numberOfInputs = np.shape(self.inputMatrix)[1]\n",
    "        \n",
    "        if not test:\n",
    "            for nodeNumber in range(len(nodeNumbers)-1):\n",
    "                self.weightMatrices.append(np.random.random_sample((nodeNumbers[nodeNumber+1], \\\n",
    "                                                                    nodeNumbers[nodeNumber+1] +1)) - .5)          \n",
    "        else:\n",
    "            self.weightMatrices.append(np.array(((1., -1., 0.), (1., 0., 1.))))\n",
    "            self.weightMatrices.append(np.array(((1., 1., 0.), (1., -1., 1.)))) \n",
    "            self.inputs = np.array((1, 0, 1))\n",
    "            \n",
    "    def run(self):\n",
    "        self.forward()\n",
    "        self.calculateErrors()\n",
    "        self.iterations = 1\n",
    "        self.outputForPlot1 = []\n",
    "        self.outputForPlot2 = []\n",
    "        while np.abs(self.error2) > self.errorTolerance and self.iterations < self.maxIterations: \n",
    "            self.backward()\n",
    "            self.forward()\n",
    "            #print('Output: ', self.outputs)\n",
    "            self.calculateErrors()\n",
    "            self.iterations += 1\n",
    "            self.outputForPlot1.append(self.outputs[-1][0])\n",
    "            self.outputForPlot2.append(self.outputs[-1][1])\n",
    "        #self.plot()\n",
    "\n",
    "        print('Iterations: ', self.iterations, '|Error|: ', self.error2, 'Output: ', self.outputs[1])\n",
    "        \n",
    "    def runMultipleInput(self):\n",
    "            self.iterationNumber = 0\n",
    "            numberOfAdjustmentsDuringIteration = 1\n",
    "            \n",
    "            while (self.iterationNumber < self.maxIterations and numberOfAdjustmentsDuringIteration != 0):\n",
    "                self.iterationNumber += 1\n",
    "                numberOfAdjustmentsDuringIteration = 0\n",
    "                \n",
    "                #print('targetMatrix', self.targetMatrix)\n",
    "\n",
    "                for inputNumber in range(self.numberOfInputs):\n",
    "                    #print('inputNumber', inputNumber)\n",
    "                    self.inputs = self.inputMatrix[:,inputNumber]\n",
    "                    self.targets = self.targetMatrix[inputNumber]\n",
    "                    self.targetLength = np.asarray([0])\n",
    "                    # FIX to allow for multidim output\n",
    "                    #print('self.targetMatrix[inputNumber] ', self.targetMatrix[inputNumber] )\n",
    "                    self.forward()\n",
    "                    self.calculateErrors()\n",
    "                    \n",
    "                    #print('self.error2', self.error2)\n",
    "                    if abs(self.error2[-1]) > self.errorTolerance:\n",
    "                        numberOfAdjustmentsDuringIteration +=1\n",
    "                        self.backward()\n",
    "                        \n",
    "            print('Iterations: ', self.iterationNumber, '|Error|: ', self.error2[-1])\n",
    "        \n",
    "    def plot(self):\n",
    "        fig, (ax, ax2) = plt.subplots(1,2)\n",
    "        ax.plot(np.arange(len(self.outputForPlot1)), self.outputForPlot1)#, label='Input 1')\n",
    "        ax2.plot(np.arange(len(self.outputForPlot2)), self.outputForPlot2)#, label='Input 2')\n",
    "        ax.set_title('Input 1')\n",
    "        ax2.set_title('Input 22')\n",
    "        plt.savefig('simple.pdf')\n",
    "        \n",
    "    def differentiateActivationFunction(self, weightedInputs):\n",
    "        if isinstance(weightedInputs, np.ndarray):\n",
    "            onesArray = np.ones(len(weightedInputs))\n",
    "        else:\n",
    "            onesArray = 1\n",
    "        out = self.activationFunction(weightedInputs)*(onesArray - self.activationFunction(weightedInputs))\n",
    "        #return 1\n",
    "        #return out      \n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        weightedInputs = []\n",
    "        print('self.inputs', self.inputs)\n",
    "        weightedInputs.append(self.weightMatrices[0] @ self.inputs)\n",
    "        self.outputs = []\n",
    "        self.outputs.append(self.activationFunction(weightedInputs[-1]))\n",
    "\n",
    "        for layer in range(1, len(self.nodeNumbers)-1):\n",
    "            outputsIncludingBias = np.concatenate([[1], self.outputs[-1]])\n",
    "            weightedInputs.append(self.weightMatrices[layer] @ outputsIncludingBias)\n",
    "            self.outputs.append(self.activationFunction(weightedInputs[-1]))\n",
    "        self.weightedInputs = weightedInputs\n",
    "        #print('self.outputs', self.outputs[-1])\n",
    "            \n",
    "    def calculateErrors(self):\n",
    "        self.error2 = 0\n",
    "        print('type(self.targets)', type(self.targets))\n",
    "        if not isinstance(self.targets, list):\n",
    "                self.error2 += (self.targets - self.outputs[-1])**2\n",
    "                #print('WRONG')\n",
    "        else:\n",
    "            for outputNodeNumber in range(len(self.outputs)):\n",
    "            #print('outputNodeNumber', outputNodeNumber)\n",
    "                self.error2 += (self.targets[outputNodeNumber] - \\\n",
    "                           self.outputs[-1][outputNodeNumber])**2\n",
    "        \n",
    "    def backward(self):\n",
    "        # Output deltas\n",
    "        self.deltaVectors = []\n",
    "        '''\n",
    "        deltaValuesOld = np.array([(self.outputs[-1][outputNumber] - self.targets[outputNumber])\\\n",
    "                      *self.differentiateActivationFunction(self.weightedInputs[-1][outputNumber]) \\\n",
    "                      for outputNumber in range(len(self.targets))])\n",
    "        '''\n",
    "        deltaValues = (self.outputs[-1] - self.targets)* self.differentiateActivationFunction(self.weightedInputs[-1])\n",
    "        self.deltaVectors.append(deltaValues)\n",
    "        \n",
    "        # Hidden deltas\n",
    "        if not isinstance(self.targets, np.ndarray):\n",
    "            targetForLoop = np.array([self.targets])\n",
    "        for layerNumber in range(len(self.nodeNumbers)-2):\n",
    "            deltaVecs = []\n",
    "            for j in range(self.nodeNumbers[-1-(layerNumber+1)+1]):\n",
    "                deltaSum = 0\n",
    "                #print('self.targetLength',self.targetLength)\n",
    "                for k in range(len(self.targetLength)):\n",
    "                    deltaSum += self.deltaVectors[-1-layerNumber][k] * self.weightMatrices[-1][k,j+1] \n",
    "                deltaVecs.append(deltaSum*self.differentiateActivationFunction(self.weightedInputs[-1][j]))\n",
    "        self.deltaVectors.insert(0, deltaVecs)\n",
    "        \n",
    "        # Output weights\n",
    "        outputsIncludingBias = np.concatenate([[1], self.outputs[-2]])\n",
    "        for j in range(self.nodeNumbers[-2] + 1):\n",
    "            #print(self.targetLength)\n",
    "            for k in range(len(self.targetLength)):\n",
    "                self.weightMatrices[-1][k, j] -= \\\n",
    "                self.learningRate*self.deltaVectors[1][k]*outputsIncludingBias[j]\n",
    "        \n",
    "        # Hidden weights\n",
    "        for inputNumber in range(self.nodeNumbers[0]+1):\n",
    "            for hiddenNodeNumber in range(self.nodeNumbers[1]): # fix indexes\n",
    "                self.weightMatrices[0][hiddenNodeNumber, inputNumber] -= self.learningRate \\\n",
    "                * self.deltaVectors[0][hiddenNodeNumber]*self.inputs[inputNumber]\n",
    "     \n",
    "#def activationFunction(x):\n",
    " #   return x\n",
    " \n",
    "\n",
    "def activationFunction(x):\n",
    "    return 1./(1+np.exp(-x))\n",
    " \n",
    "\n",
    "numberOfNodes = [2,2,2]\n",
    "activationFunction = activationFunction\n",
    "learningRate = 0.01\n",
    "targetMatrix = np.array(((0), (1), (1), (0))).T\n",
    "inputMatrix = np.array(((-1,0, 0), (-1, 0, 1), (-1,1, 0), (-1,1,1))).T\n",
    "errorTolerance = 1e-3\n",
    "maxIterations= 10000\n",
    "test = False\n",
    "\n",
    "nn=NN(numberOfNodes, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations, test)\n",
    "#nn.runMultipleInput()\n",
    "'''\n",
    "print('nn.weightMatrices',nn.weightMatrices)\n",
    "\n",
    "nn.forward()\n",
    "print('nn.weightedInputs',nn.weightedInputs)\n",
    "print('nn.outputs',nn.outputs)\n",
    "\n",
    "nn.calculateErrors()\n",
    "print('nn.error2',nn.error2)\n",
    "\n",
    "nn.backward()\n",
    "print('nn.deltaVectors',nn.deltaVectors)\n",
    "print('weightMatrices', nn.weightMatrices)\n",
    "\n",
    "nn.run()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn2.inputs [1 0 1]\n",
      "nn.weightMatrices [array([[ 1., -1.,  0.],\n",
      "       [ 1.,  0.,  1.]]), array([[ 1.,  1.,  0.],\n",
      "       [ 1., -1.,  1.]])]\n",
      "self.inputs [1 0 1]\n",
      "nn.weightedInputs [array([1., 2.]), array([2., 2.])]\n",
      "nn.outputs [array([1., 2.]), array([2., 2.])]\n",
      "type(self.targets) <class 'list'>\n",
      "nn.error2 5.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5bc8aa7b6bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nn.error2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mnn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#print('nn.deltaVectors',nn2.deltaVectors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#print('weightMatrices', nn2.weightMatrices)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-44b8d20d9eb5>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m                       for outputNumber in range(len(self.targets))])\n\u001b[1;32m    123\u001b[0m         '''\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mdeltaValues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifferentiateActivationFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightedInputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeltaVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltaValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "## Slides. Must change derivative inside class to 1\n",
    "def activationFunction(x):\n",
    "    return x\n",
    "\n",
    "numberOfNodes,  activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations = \\\n",
    "[2,2,2], activationFunction, 0.1, np.array([1, 0]), np.array([0, 1]), 1e-6, 100\n",
    "test = True\n",
    "\n",
    "\n",
    "nn2=NN(numberOfNodes, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations, test=True)\n",
    "\n",
    "\n",
    "print('nn2.inputs',nn2.inputs)\n",
    "\n",
    "print('nn.weightMatrices',nn2.weightMatrices)\n",
    "\n",
    "nn2.forward()\n",
    "\n",
    "print('nn.weightedInputs',nn2.weightedInputs)\n",
    "print('nn.outputs',nn2.outputs)\n",
    "\n",
    "nn2.calculateErrors()\n",
    "print('nn.error2',nn2.error2)\n",
    "\n",
    "nn2.backward()\n",
    "#print('nn.deltaVectors',nn2.deltaVectors)\n",
    "#print('weightMatrices', nn2.weightMatrices)\n",
    "'''\n",
    "#nn2.run()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.inputs [1 0 1]\n",
      "type(self.targets) <class 'list'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a175db6a4e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnn3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfNodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivationFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorTolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnn3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-c9484d675cef>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputForPlot2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorTolerance\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxIterations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m#print('Output: ', self.outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-c9484d675cef>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetLength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mdeltaSum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeltaVectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlayerNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightMatrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mdeltaVecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltaSum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifferentiateActivationFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightedInputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeltaVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltaVecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-c9484d675cef>\u001b[0m in \u001b[0;36mdifferentiateActivationFunction\u001b[0;34m(self, weightedInputs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0monesArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivationFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweightedInputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monesArray\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivationFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweightedInputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m#return out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-a175db6a4e13>\u001b[0m in \u001b[0;36mactivationFunction\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mactivationFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0monesArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnumberOfNodes\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mactivationFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorTolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivationFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "def activationFunction(x):\n",
    "    onesArray = np.ones(len(x))\n",
    "    return 1./(1+np.exp(-x)) \n",
    "\n",
    "numberOfNodes,  activationFunction, learningRate, targets, inputs, errorTolerance, maxIterations = \\\n",
    "[2,2,2], activationFunction, 0.1, np.array([1, 0]), np.array([0, 1]), 1e-6, 100000\n",
    "inputs = np.array((1, 0, 1))\n",
    "\n",
    "nn3=NN(numberOfNodes, activationFunction, learningRate, targets, inputs, errorTolerance, maxIterations, test=True)\n",
    "nn3.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
