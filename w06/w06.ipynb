{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Last week we used the activation function. Why is this not used with backpropagation?\n",
    "\n",
    "__A:__ The function is not differentiable.\n",
    "\n",
    "# 2 What is the minimum number of hidden neuron layers needed in order to approximate an arbitrary continuous function, and why?\n",
    "\n",
    "__A:__ One hidden layer is the minimum. \"Universal approximation theorem: Any continuous function\n",
    "can be approximated by a neural network with a single\n",
    "hidden layer\", slide 54 https://www.uio.no/studier/emner/matnat/ifi/INF3490/h18/timeplan/slides/lecture6-1pp.pdf\n",
    "\n",
    "\n",
    "Without a hidden layer, it is impossible to approximate non-linear separable problems. The first layer gives lines, and the second layer opens up the dimension to two, so e.g. traingles can be made. Furthermore, a compbination of enough traingles can approximate any shape. See slide 12 https://www.uio.no/studier/emner/matnat/ifi/INF3490/h18/timeplan/slides/lecture6-1pp.pdf\n",
    "\n",
    "<mark> UNCLEAR <br>\n",
    "    \n",
    "    \n",
    "    \n",
    "# 3 Why do we use a validation set? Describe how the three different cross-validation methods presented in the lecture slides work, and what their advantages and disadvantages are.\n",
    "We want the model to generalize well, meaning that it works well on other data than the data the model was estimated on. When fitting the model to the full dataset, the model will typically not fit well for other data. In oredr to create a model that generalizes well, the data is split into a training and a validation set. The model is fit to the training set, and is then evaluated on the validation set. The model performance on the validation set describes how well the model generalizes. <br>\n",
    "\n",
    "Three crossvalidation methods. <br> \n",
    "1) Split into training and validation (and possible test). Works as the previous paragraph. <br>\n",
    "2) K-fold cross-validation. Split into K number of folds. Each fold performs as validation set once, while at the same time the model is fit to the remaining folds. <br>\n",
    "3) Bootstrapping. Draw random observations with replacement and use the rest as validation. Repeat.\n",
    "\n",
    "# 4 Implement the MLP shown below, and train it to correctly perform the XOR function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.weightMatrices [array([[-0.46099131, -0.24030389,  0.0155826 ],\n",
      "       [ 0.01491849,  0.47713365,  0.10239317]]), array([[ 0.29723732, -0.3099767 , -0.14569952]])]\n",
      "self.inputs [-1  0  0]\n",
      "self.targets 0\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[ 0.29723732 -0.3099767  -0.14569952]]\n",
      "outputsIncludingBias [1.         0.61324932 0.49627045]\n",
      "self.error2 [0.25878445]\n",
      "weightedInputs [array([ 0.46099131, -0.01491849]), array([0.03483795])]\n",
      "self.weightedInputs[-1] [0.03483795]\n",
      "j 0\n",
      "j 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-92bb396ced73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfNodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivationFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorTolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunMultipleInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m '''\n\u001b[1;32m    207\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nn.weightMatrices'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightMatrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-92bb396ced73>\u001b[0m in \u001b[0;36mrunMultipleInput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorTolerance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mnumberOfAdjustmentsDuringIteration\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'self.weightMatrices'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightMatrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorForPlot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfAdjustmentsDuringIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-92bb396ced73>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetLength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mdeltaSum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeltaVectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlayerNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightMatrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mdeltaVecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltaSum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifferentiateActivationFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightedInputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeltaVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltaVecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "class NN:\n",
    "    \"\"\" 2 layer (1 hidden). Single input combination of 2 intergers. Output 2 integers\"\"\"\n",
    "    \n",
    "    def __init__(self, nodeNumbers, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, \\\n",
    "                 maxIterations, test=False, singleOutput=False):\n",
    "        self.nodeNumbers, self.activationFunction, self.learningRate, self.targetMatrix, self.inputMatrix, self.errorTolerance,  \\\n",
    "        self.maxIterations, self.test, self.singleOutput= \\\n",
    "        nodeNumbers, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance,\\\n",
    "        maxIterations, test, singleOutput\n",
    "        \n",
    "        \n",
    "        self.weightMatrices = []\n",
    "        \n",
    "        # If single input\n",
    "        if self.inputMatrix.ndim == 1:\n",
    "            self.inputs = self.inputMatrix.tolist()\n",
    "            self.targets = self.targetMatrix.tolist()\n",
    "            self.targetLength = self.targets\n",
    "        else:\n",
    "            self.numberOfInputs = np.shape(self.inputMatrix)[1]\n",
    "        \n",
    "        if not test:\n",
    "            #print('nodeNumbers',nodeNumbers)\n",
    "            for nodeNumber in range(len(nodeNumbers[1:])):\n",
    "                #print('nodeNumber', nodeNumber)\n",
    "                #print('nodeNumbers[nodeNumber]', nodeNumbers[nodeNumber])\n",
    "                self.weightMatrices.append(np.random.random_sample((nodeNumbers[nodeNumber+1], \\\n",
    "                                                                    nodeNumbers[nodeNumber]+1)) - .5)          \n",
    "        else:\n",
    "            self.weightMatrices.append(np.array(((1., -1., 0.), (1., 0., 1.))))\n",
    "            self.weightMatrices.append(np.array(((1., 1., 0.), (1., -1., 1.)))) \n",
    "            self.inputs = np.array((1, 0, 1))\n",
    "            \n",
    "        print('self.weightMatrices',self.weightMatrices) \n",
    "            \n",
    "    def run(self):\n",
    "        self.forward()\n",
    "        self.calculateErrors()\n",
    "        self.iterations = 1\n",
    "        self.outputForPlot1 = []\n",
    "        self.outputForPlot2 = []\n",
    "        while np.abs(self.error2) > self.errorTolerance and self.iterations < self.maxIterations: \n",
    "            self.backward()\n",
    "            self.forward()\n",
    "            #print('Output: ', self.outputs)\n",
    "            self.calculateErrors()\n",
    "            self.iterations += 1\n",
    "            self.outputForPlot1.append(self.outputs[-1][0])\n",
    "            self.outputForPlot2.append(self.outputs[-1][1])\n",
    "        #self.plot()\n",
    "\n",
    "        print('Iterations: ', self.iterations, '|Error|: ', self.error2, 'Output: ', self.outputs[1])\n",
    "        \n",
    "    def runMultipleInput(self):\n",
    "        self.iterationNumber = 0\n",
    "        numberOfAdjustmentsDuringIteration = 1\n",
    "        \n",
    "        self.errorForPlot = []\n",
    "        while (self.iterationNumber < self.maxIterations and numberOfAdjustmentsDuringIteration != 0):\n",
    "            self.iterationNumber += 1\n",
    "            numberOfAdjustmentsDuringIteration = 0\n",
    "\n",
    "            #print('targetMatrix', self.targetMatrix)\n",
    "\n",
    "            for inputNumber in range(self.numberOfInputs):\n",
    "                #print('inputNumber', inputNumber)\n",
    "                self.inputs = self.inputMatrix[:,inputNumber]\n",
    "                print('self.inputs',self.inputs)\n",
    "                self.targets = self.targetMatrix[inputNumber]\n",
    "                print('self.targets',self.targets)\n",
    "                self.targetLength = np.asarray([0])\n",
    "                # FIX to allow for multidim output\n",
    "                #print('self.targetMatrix[inputNumber] ', self.targetMatrix[inputNumber] )\n",
    "                self.forward()\n",
    "                self.calculateErrors()\n",
    "                print('self.error2', self.error2)\n",
    "\n",
    "                #print('self.error2', self.error2)\n",
    "                \n",
    "                if abs(self.error2[-1]) > self.errorTolerance:\n",
    "                    numberOfAdjustmentsDuringIteration +=1\n",
    "                    self.backward()\n",
    "                    print('self.weightMatrices', self.weightMatrices)\n",
    "            self.errorForPlot.append(numberOfAdjustmentsDuringIteration)\n",
    "\n",
    "        print('Iterations: ', self.iterationNumber, '|Error|: ', self.error2[-1])\n",
    "        self.plotError()\n",
    "        \n",
    "    def plotError(self):\n",
    "        plt.plot()\n",
    "        plt.plot(np.arange(len(self.errorForPlot)), self.errorForPlot)\n",
    "        \n",
    "    def plot(self):\n",
    "        fig, (ax, ax2) = plt.subplots(1,2)\n",
    "        ax.plot(np.arange(len(self.outputForPlot1)), self.outputForPlot1)#, label='Input 1')\n",
    "        ax2.plot(np.arange(len(self.outputForPlot2)), self.outputForPlot2)#, label='Input 2')\n",
    "        ax.set_title('Input 1')\n",
    "        ax2.set_title('Input 22')\n",
    "        plt.savefig('simple.pdf')\n",
    "        \n",
    "    def differentiateActivationFunction(self, weightedInputs):\n",
    "        if isinstance(weightedInputs, np.ndarray):\n",
    "            if weightedInputs.ndim == 1:\n",
    "                onesArray = np.ones(len(weightedInputs))\n",
    "        else:\n",
    "            onesArray = 1\n",
    "        out = self.activationFunction(weightedInputs)*(onesArray - self.activationFunction(weightedInputs))\n",
    "        #print(self.activationFunction(weightedInputs), onesArray, out)\n",
    "        #print('out ', out)\n",
    "        #return 1\n",
    "        return out\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        weightedInputs = []\n",
    "        #print('self.inputs', self.inputs)\n",
    "        weightedInputs.append(self.weightMatrices[0] @ self.inputs)\n",
    "        self.outputs = []\n",
    "        self.outputs.append(self.activationFunction(weightedInputs[-1]))\n",
    "\n",
    "        for layer in range(1, len(self.nodeNumbers)-1):\n",
    "            outputsIncludingBias = np.concatenate([[1], self.outputs[-1]])\n",
    "            print('layer', layer)\n",
    "            print('self.weightMatrices[layer]', self.weightMatrices[layer])\n",
    "            print('outputsIncludingBias', outputsIncludingBias)\n",
    "            weightedInputs.append(self.weightMatrices[layer] @ outputsIncludingBias)\n",
    "            self.outputs.append(self.activationFunction(weightedInputs[-1]))\n",
    "        self.weightedInputs = weightedInputs\n",
    "        #print('self.outputs', self.outputs[-1])\n",
    "            \n",
    "    def calculateErrors(self):\n",
    "        self.error2 = 0\n",
    "        if not isinstance(self.targets, list):\n",
    "                self.error2 += (self.targets - self.outputs[-1])**2\n",
    "                #print('WRONG')\n",
    "        else:\n",
    "            for outputNodeNumber in range(len(self.outputs)):\n",
    "            #print('outputNodeNumber', outputNodeNumber)\n",
    "                self.error2 += (self.targets[outputNodeNumber] - \\\n",
    "                           self.outputs[-1][outputNodeNumber])**2\n",
    "        \n",
    "    def backward(self):\n",
    "        # Output deltas\n",
    "        self.deltaVectors = []\n",
    "        '''\n",
    "        deltaValuesOld = np.array([(self.outputs[-1][outputNumber] - self.targets[outputNumber])\\\n",
    "                      *self.differentiateActivationFunction(self.weightedInputs[-1][outputNumber]) \\\n",
    "                      for outputNumber in range(len(self.targets))])\n",
    "        '''\n",
    "        print('weightedInputs',self.weightedInputs)\n",
    "        deltaValues = (self.outputs[-1] - self.targets)* self.differentiateActivationFunction(self.weightedInputs[-1])\n",
    "        self.deltaVectors.append(deltaValues)\n",
    "        \n",
    "        # Hidden deltas\n",
    "        if not isinstance(self.targets, np.ndarray):\n",
    "            targetForLoop = np.array([self.targets])\n",
    "        for layerNumber in range(len(self.nodeNumbers)-2):\n",
    "            \n",
    "            deltaVecs = []\n",
    "            #for j in range(self.nodeNumbers[(layerNumber+1)+1]):\n",
    "            print('self.weightedInputs[-1]',self.weightedInputs[-1])\n",
    "            for j in range(2):\n",
    "                print('j', j)\n",
    "                deltaSum = 0\n",
    "                #print('self.targetLength',self.targetLength)\n",
    "                for k in range(len(self.targetLength)):\n",
    "                    deltaSum += self.deltaVectors[-1-layerNumber][k] * self.weightMatrices[-1][k,j+1] \n",
    "                deltaVecs.append(deltaSum*self.differentiateActivationFunction(self.weightedInputs[-1][j]))\n",
    "        self.deltaVectors.insert(0, deltaVecs)\n",
    "        \n",
    "        print('deltaVectors', self.deltaVectors)\n",
    "        \n",
    "        # Output weights\n",
    "        outputsIncludingBias = np.concatenate([[1], self.outputs[-2]])\n",
    "        for j in range(self.nodeNumbers[-2] + 1):\n",
    "            #print(self.targetLength)\n",
    "            for k in range(len(self.targetLength)):\n",
    "                self.weightMatrices[-1][k, j] -= \\\n",
    "                self.learningRate*self.deltaVectors[1][k]*outputsIncludingBias[j]\n",
    "        print('self.weightMatrices',self.weightMatrices)\n",
    "        # Hidden weights\n",
    "        print('self.weightMatrices[0]', self.weightMatrices[0])\n",
    "        print('self.deltaVectors[0]', self.deltaVectors[0])\n",
    "        print('self.inputs', self.inputs)\n",
    "        for inputNumber in range(self.nodeNumbers[0]+1):\n",
    "            for hiddenNodeNumber in range(self.nodeNumbers[1]): # fix indexes\n",
    "                print('inputNumber', inputNumber, 'hiddenNodeNumber', hiddenNodeNumber)\n",
    "                \n",
    "                self.weightMatrices[0][hiddenNodeNumber, inputNumber] -= self.learningRate \\\n",
    "                * self.deltaVectors[0][hiddenNodeNumber]*self.inputs[inputNumber]\n",
    "     \n",
    "#def activationFunction(x):\n",
    " #   return x\n",
    " \n",
    "\n",
    "def activationFunction(x):\n",
    "    return 1./(1+np.exp(-x))\n",
    " \n",
    "\n",
    "numberOfNodes = [2,2,1]\n",
    "activationFunction = activationFunction\n",
    "learningRate = 0.01\n",
    "targetMatrix = np.array(((0), (1), (1), (0))).T\n",
    "inputMatrix = np.array(((-1,0, 0), (-1, 0, 1), (-1,1, 0), (-1,1,1))).T\n",
    "errorTolerance = 1e-3\n",
    "maxIterations= 3\n",
    "test = False\n",
    "singleOutput = True\n",
    "\n",
    "nn=NN(numberOfNodes, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations, test)\n",
    "nn.runMultipleInput()\n",
    "'''\n",
    "print('nn.weightMatrices',nn.weightMatrices)\n",
    "\n",
    "nn.forward()\n",
    "print('nn.weightedInputs',nn.weightedInputs)\n",
    "print('nn.outputs',nn.outputs)\n",
    "\n",
    "nn.calculateErrors()\n",
    "print('nn.error2',nn.error2)\n",
    "\n",
    "nn.backward()\n",
    "print('nn.deltaVectors',nn.deltaVectors)\n",
    "print('weightMatrices', nn.weightMatrices)\n",
    "\n",
    "nn.run()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.weightMatrices [array([[-0.04321274,  0.0708538 ,  0.28329251],\n",
      "       [-0.46904401,  0.2077519 , -0.32281236]]), array([[-0.12063922,  0.06255361, -0.35198749],\n",
      "       [-0.37555948, -0.18998248,  0.38851104]])]\n",
      "nn2.inputs [1, 0, 1]\n",
      "nn.weightMatrices [array([[-0.04321274,  0.0708538 ,  0.28329251],\n",
      "       [-0.46904401,  0.2077519 , -0.32281236]]), array([[-0.12063922,  0.06255361, -0.35198749],\n",
      "       [-0.37555948, -0.18998248,  0.38851104]])]\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.12063922  0.06255361 -0.35198749]\n",
      " [-0.37555948 -0.18998248  0.38851104]]\n",
      "outputsIncludingBias [ 1.          0.24007977 -0.79185637]\n",
      "nn.weightedInputs [array([ 0.24007977, -0.79185637]), array([ 0.17310218, -0.72881538])]\n",
      "nn.outputs [array([ 0.24007977, -0.79185637]), array([ 0.17310218, -0.72881538])]\n",
      "nn.error2 1.21493186855847\n",
      "self.weightMatrices[0] [[-0.04321274  0.0708538   0.28329251]\n",
      " [-0.46904401  0.2077519  -0.32281236]]\n",
      "self.deltaVectors[0] [-0.02603167455412636, -0.5020170952018476]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "nn.deltaVectors [[-0.02603167455412636, -0.5020170952018476], array([-0.11836035,  0.91829807])]\n",
      "weightMatrices [array([[-0.04060957,  0.0708538 ,  0.28589568],\n",
      "       [-0.4188423 ,  0.2077519 , -0.27261065]]), array([[-0.10880318,  0.0653952 , -0.36135993],\n",
      "       [-0.46738929, -0.21202896,  0.46122706]])]\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.10880318  0.0653952  -0.36135993]\n",
      " [-0.46738929 -0.21202896  0.46122706]]\n",
      "outputsIncludingBias [ 1.          0.24528611 -0.69145295]\n",
      "self.weightMatrices[0] [[-0.04060957  0.0708538   0.28589568]\n",
      " [-0.4188423   0.2077519  -0.27261065]]\n",
      "self.deltaVectors[0] [-0.037239442299471, -0.9804355517699227]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.0976415   0.068133   -0.36907771]\n",
      " [-0.5965805  -0.24371777  0.5505567 ]]\n",
      "outputsIncludingBias [ 1.          0.252734   -0.49536584]\n",
      "self.weightMatrices[0] [[-0.03688562  0.0708538   0.28961962]\n",
      " [-0.32079874  0.2077519  -0.1745671 ]]\n",
      "self.deltaVectors[0] [-0.038002281637717544, -1.7106455467783486]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.08939088  0.07021822 -0.37316479]\n",
      " [-0.76390888 -0.28600734  0.63344546]]\n",
      "outputsIncludingBias [ 1.          0.26033445 -0.15323673]\n",
      "self.weightMatrices[0] [[-0.0330854   0.0708538   0.29341985]\n",
      " [-0.14973419  0.2077519  -0.00350254]]\n",
      "self.deltaVectors[0] [0.006826184903618771, -1.9325737914166312]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.09082276  0.06984545 -0.37294537]\n",
      " [-0.93326627 -0.33009691  0.65939724]]\n",
      "outputsIncludingBias [1.         0.25896922 0.23327803]\n",
      "self.weightMatrices[0] [[-0.03376801  0.0708538   0.29273723]\n",
      " [ 0.04352319  0.2077519   0.18975484]]\n",
      "self.deltaVectors[0] [0.08253460038013377, -1.3546820341196022]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.11230686  0.06428173 -0.37795714]\n",
      " [-1.07278174 -0.36622712  0.62685134]]\n",
      "outputsIncludingBias [1.         0.2424623  0.50421443]\n",
      "self.weightMatrices[0] [[-0.04202147  0.0708538   0.28448377]\n",
      " [ 0.17899139  0.2077519   0.32522304]]\n",
      "self.deltaVectors[0] [0.16737459257556436, -1.0097161582428271]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.15991471  0.05273862 -0.40196171]\n",
      " [-1.20471508 -0.39821598  0.56032865]]\n",
      "outputsIncludingBias [1.         0.20898738 0.70615766]\n",
      "self.weightMatrices[0] [[-0.05875893  0.0708538   0.26774631]\n",
      " [ 0.27996301  0.2077519   0.42619465]]\n",
      "self.deltaVectors[0] [0.3428953769034228, -0.8223265362969336]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.24874559  0.03417409 -0.46469031]\n",
      " [-1.35536185 -0.42969925  0.45394828]]\n",
      "outputsIncludingBias [1.         0.1404083  0.87062297]\n",
      "self.weightMatrices[0] [[-0.09304847  0.0708538   0.23345677]\n",
      " [ 0.36219566  0.2077519   0.50842731]]\n",
      "self.deltaVectors[0] [0.9021956141983655, -0.2807463236853168]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.42498727  0.00942829 -0.61813037]\n",
      " [-1.56576914 -0.45924218  0.27076286]]\n",
      "outputsIncludingBias [ 1.         -0.04003082  0.92677224]\n",
      "self.weightMatrices[0] [[-0.18326803  0.0708538   0.14323721]\n",
      " [ 0.3902703   0.2077519   0.53650194]]\n",
      "self.deltaVectors[0] [3.460831697029057, 4.223748563599583]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.82357344  0.02538402 -0.98752897]\n",
      " [-1.9517523  -0.44379096 -0.08695562]]\n",
      "outputsIncludingBias [ 1.         -0.73219716  0.08202252]\n",
      "self.weightMatrices[0] [[-0.5293512   0.0708538  -0.20284596]\n",
      " [-0.03210456  0.2077519   0.11412708]]\n",
      "self.deltaVectors[0] [5.38663943334394, 17.142683658750222]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-1.16500766  0.27538119 -1.01553426]\n",
      " [-2.65495347  0.07109094 -0.14463395]]\n",
      "outputsIncludingBias [ 1.         -1.80952505 -3.34651421]\n",
      "self.weightMatrices[0] [[-1.06801515  0.0708538  -0.7415099 ]\n",
      " [-1.74637293  0.2077519  -1.60014128]]\n",
      "self.deltaVectors[0] [-1.252903353110527, 11.921598171013752]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-1.07122206  0.10567378 -1.32938914]\n",
      " [-4.39978304  3.22840376  5.69446301]]\n",
      "outputsIncludingBias [ 1.         -1.55894438 -5.73083384]\n",
      "self.weightMatrices[0] [[-0.94272481  0.0708538  -0.61621957]\n",
      " [-2.93853274  0.2077519  -2.7923011 ]]\n",
      "self.deltaVectors[0] [-8451889.822034111, -786678986.8188195]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[ 1.74201698e+01 -2.87213776e+01 -1.07300483e+02]\n",
      " [-7.62551761e+03  1.18841272e+04  4.36810544e+04]]\n",
      "outputsIncludingBias [1.00000000e+00 1.69037641e+06 1.57335792e+08]\n",
      "self.weightMatrices[0] [[8.45188039e+05 7.08538023e-02 8.45188366e+05]\n",
      " [7.86678957e+07 2.07751899e-01 7.86678959e+07]]\n",
      "self.deltaVectors[0] [1.1155389172543539e+63, 6.795701579945112e+68]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-4.85321001e+29 -8.20375169e+35 -7.63583639e+37]\n",
      " [ 3.27464866e+37  5.53538884e+43  5.15219440e+45]]\n",
      "outputsIncludingBias [ 1.00000000e+00 -2.23107783e+62 -1.35914032e+68]\n",
      "self.weightMatrices[0] [[-1.11553892e+62  7.08538023e-02 -1.11553892e+62]\n",
      " [-6.79570158e+67  2.07751899e-01 -6.79570158e+67]]\n",
      "self.deltaVectors[0] [-inf, -inf]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[ inf -inf -inf]\n",
      " [-inf  inf  inf]]\n",
      "outputsIncludingBias [ 1. nan nan]\n",
      "Iterations:  14 |Error|:  nan Output:  [nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/ipykernel_launcher.py:146: RuntimeWarning: overflow encountered in multiply\n",
      "/home/k/.local/lib/python3.6/site-packages/ipykernel_launcher.py:177: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "## Slides. Must change derivative inside class to 1\n",
    "def activationFunction(x):\n",
    "    return x\n",
    "\n",
    "numberOfNodes,  activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations = \\\n",
    "[2,2,2], activationFunction, 0.1, np.array([1, 0]), np.array((1, 0, 1)), 1e-6, 100\n",
    "test = True\n",
    "\n",
    "\n",
    "nn2=NN(numberOfNodes, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations, test=False)\n",
    "\n",
    "\n",
    "print('nn2.inputs',nn2.inputs)\n",
    "\n",
    "print('nn.weightMatrices',nn2.weightMatrices)\n",
    "\n",
    "nn2.forward()\n",
    "\n",
    "print('nn.weightedInputs',nn2.weightedInputs)\n",
    "print('nn.outputs',nn2.outputs)\n",
    "\n",
    "nn2.calculateErrors()\n",
    "print('nn.error2',nn2.error2)\n",
    "\n",
    "nn2.backward()\n",
    "print('nn.deltaVectors',nn2.deltaVectors)\n",
    "print('weightMatrices', nn2.weightMatrices)\n",
    "\n",
    "nn2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  100000 |Error|:  5.3734953521503506e-05 Output:  [0.99481832 0.00518509]\n"
     ]
    }
   ],
   "source": [
    "def activationFunction(x):\n",
    "    return 1./(1+np.exp(-x)) \n",
    "\n",
    "numberOfNodes,  activationFunction, learningRate, targets, inputs, errorTolerance, maxIterations = \\\n",
    "[2,2,2], activationFunction, 0.1, np.array([1, 0]), np.array((1, 0, 1)), 1e-6, 100000\n",
    "inputs = np.array((1, 0, 1))\n",
    "\n",
    "nn3=NN(numberOfNodes, activationFunction, learningRate, targets, inputs, errorTolerance, maxIterations, test=False)\n",
    "nn3.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the lecture slides the backpropagation deltas are first presented as $\\delta_k = (y_k − t_k )y_k (1 − y_k )$. What does this tell us about the activation function in use?\n",
    "\n",
    "The Sigmoid function is used as activation function. We have $\\delta_k = (y_k -t_k) f'(a)$, where $a$ is the input to the acitivation functino in the output layer. When the Sigmoid is used we have $f'(a_k) = sigmoid(a_k) (1 - sigmoid(a_k)) = y_k(1-y_k)$, which is what we have.\n",
    "\n",
    "# You are to design an MLP that would learn to hyphenate words correctly. You would have a dictionary that shows correct hyphenation examples for lots of words. Think about the following: \n",
    "\n",
    "## What should the input to the neural net be?\n",
    "Traning face: The full words without hypenation as input and the correct words from the dictionary.\n",
    "Else: Full words without hypenation.\n",
    "\n",
    "<mark> Sol:Input = 2 letters.?? So not words?<mark>\n",
    "\n",
    "## How should this input be encoded to work well with the classifier?\n",
    "NN needs numbers. One interger per letter.\n",
    "\n",
    "## How is should the output be encoded?\n",
    "True and False --> 1d output. True = hyphenate.\n",
    "\n",
    "## How many layers do you need?\n",
    "Don' know. Suspect it is not a linear separable problem, so 1 hidden layer as a minimum.\n",
    "\n",
    "## How many neurons should there be in each layer?\n",
    "Experiment. Sol: Start with 2N/3, N = inputnumber, in 1st hidden, and N/3 sedond. <mark> Where does this come from?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
