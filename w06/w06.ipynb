{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Last week we used the activation function. Why is this not used with backpropagation?\n",
    "\n",
    "__A:__ The function is not differentiable.\n",
    "\n",
    "# 2 What is the minimum number of hidden neuron layers needed in order to approximate an arbitrary continuous function, and why?\n",
    "\n",
    "__A:__ One hidden layer is the minimum. \"Universal approximation theorem: Any continuous function\n",
    "can be approximated by a neural network with a single\n",
    "hidden layer\", slide 54 https://www.uio.no/studier/emner/matnat/ifi/INF3490/h18/timeplan/slides/lecture6-1pp.pdf\n",
    "\n",
    "\n",
    "Without a hidden layer, it is impossible to approximate non-linear separable problems. The first layer gives lines, and the second layer opens up the dimension to two, so e.g. traingles can be made. Furthermore, a compbination of enough traingles can approximate any shape. See slide 12 https://www.uio.no/studier/emner/matnat/ifi/INF3490/h18/timeplan/slides/lecture6-1pp.pdf\n",
    "\n",
    "<mark> UNCLEAR <br>\n",
    "    \n",
    "    \n",
    "    \n",
    "# 3 Why do we use a validation set? Describe how the three different cross-validation methods presented in the lecture slides work, and what their advantages and disadvantages are.\n",
    "We want the model to generalize well, meaning that it works well on other data than the data the model was estimated on. When fitting the model to the full dataset, the model will typically not fit well for other data. In oredr to create a model that generalizes well, the data is split into a training and a validation set. The model is fit to the training set, and is then evaluated on the validation set. The model performance on the validation set describes how well the model generalizes. <br>\n",
    "\n",
    "Three crossvalidation methods. <br> \n",
    "1) Split into training and validation (and possible test). Works as the previous paragraph. <br>\n",
    "2) K-fold cross-validation. Split into K number of folds. Each fold performs as validation set once, while at the same time the model is fit to the remaining folds. <br>\n",
    "3) Bootstrapping. Draw random observations with replacement and use the rest as validation. Repeat.\n",
    "\n",
    "# 4 Implement the MLP shown below, and train it to correctly perform the XOR function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.weightMatrices [array([[-0.11147097,  0.26666042,  0.29550986],\n",
      "       [-0.43251074, -0.00433381,  0.45702758]]), array([[0.00525447, 0.36373147, 0.0160505 ]])]\n",
      "self.inputs [-1  0  0]\n",
      "self.targets 0\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[0.00525447 0.36373147 0.0160505 ]]\n",
      "outputsIncludingBias [1.         0.52783892 0.60647305]\n",
      "self.error2 [0.30421968]\n",
      "weightedInputs [array([0.11147097, 0.43251074]), array([0.2069803])]\n",
      "self.weightedInputs[-1] [0.2069803]\n",
      "j 0\n",
      "j 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92bb396ced73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfNodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivationFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorTolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunMultipleInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m '''\n\u001b[1;32m    207\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nn.weightMatrices'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightMatrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-92bb396ced73>\u001b[0m in \u001b[0;36mrunMultipleInput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorTolerance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mnumberOfAdjustmentsDuringIteration\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'self.weightMatrices'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightMatrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorForPlot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfAdjustmentsDuringIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-92bb396ced73>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetLength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mdeltaSum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeltaVectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlayerNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightMatrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mdeltaVecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltaSum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifferentiateActivationFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightedInputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeltaVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltaVecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "class NN:\n",
    "    \"\"\" 2 layer (1 hidden). Single input combination of 2 intergers. Output 2 integers\"\"\"\n",
    "    \n",
    "    def __init__(self, nodeNumbers, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, \\\n",
    "                 maxIterations, test=False, singleOutput=False):\n",
    "        self.nodeNumbers, self.activationFunction, self.learningRate, self.targetMatrix, self.inputMatrix, self.errorTolerance,  \\\n",
    "        self.maxIterations, self.test, self.singleOutput= \\\n",
    "        nodeNumbers, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance,\\\n",
    "        maxIterations, test, singleOutput\n",
    "        \n",
    "        \n",
    "        self.weightMatrices = []\n",
    "        \n",
    "        # If single input\n",
    "        if self.inputMatrix.ndim == 1:\n",
    "            self.inputs = self.inputMatrix.tolist()\n",
    "            self.targets = self.targetMatrix.tolist()\n",
    "            self.targetLength = self.targets\n",
    "        else:\n",
    "            self.numberOfInputs = np.shape(self.inputMatrix)[1]\n",
    "        \n",
    "        if not test:\n",
    "            #print('nodeNumbers',nodeNumbers)\n",
    "            for nodeNumber in range(len(nodeNumbers[1:])):\n",
    "                #print('nodeNumber', nodeNumber)\n",
    "                #print('nodeNumbers[nodeNumber]', nodeNumbers[nodeNumber])\n",
    "                self.weightMatrices.append(np.random.random_sample((nodeNumbers[nodeNumber+1], \\\n",
    "                                                                    nodeNumbers[nodeNumber]+1)) - .5)          \n",
    "        else:\n",
    "            self.weightMatrices.append(np.array(((1., -1., 0.), (1., 0., 1.))))\n",
    "            self.weightMatrices.append(np.array(((1., 1., 0.), (1., -1., 1.)))) \n",
    "            self.inputs = np.array((1, 0, 1))\n",
    "            \n",
    "        print('self.weightMatrices',self.weightMatrices) \n",
    "            \n",
    "    def run(self):\n",
    "        self.forward()\n",
    "        self.calculateErrors()\n",
    "        self.iterations = 1\n",
    "        self.outputForPlot1 = []\n",
    "        self.outputForPlot2 = []\n",
    "        while np.abs(self.error2) > self.errorTolerance and self.iterations < self.maxIterations: \n",
    "            self.backward()\n",
    "            self.forward()\n",
    "            #print('Output: ', self.outputs)\n",
    "            self.calculateErrors()\n",
    "            self.iterations += 1\n",
    "            self.outputForPlot1.append(self.outputs[-1][0])\n",
    "            self.outputForPlot2.append(self.outputs[-1][1])\n",
    "        #self.plot()\n",
    "\n",
    "        print('Iterations: ', self.iterations, '|Error|: ', self.error2, 'Output: ', self.outputs[1])\n",
    "        \n",
    "    def runMultipleInput(self):\n",
    "        self.iterationNumber = 0\n",
    "        numberOfAdjustmentsDuringIteration = 1\n",
    "        \n",
    "        self.errorForPlot = []\n",
    "        while (self.iterationNumber < self.maxIterations and numberOfAdjustmentsDuringIteration != 0):\n",
    "            self.iterationNumber += 1\n",
    "            numberOfAdjustmentsDuringIteration = 0\n",
    "\n",
    "            #print('targetMatrix', self.targetMatrix)\n",
    "\n",
    "            for inputNumber in range(self.numberOfInputs):\n",
    "                #print('inputNumber', inputNumber)\n",
    "                self.inputs = self.inputMatrix[:,inputNumber]\n",
    "                print('self.inputs',self.inputs)\n",
    "                self.targets = self.targetMatrix[inputNumber]\n",
    "                print('self.targets',self.targets)\n",
    "                self.targetLength = np.asarray([0])\n",
    "                # FIX to allow for multidim output\n",
    "                #print('self.targetMatrix[inputNumber] ', self.targetMatrix[inputNumber] )\n",
    "                self.forward()\n",
    "                self.calculateErrors()\n",
    "                print('self.error2', self.error2)\n",
    "\n",
    "                #print('self.error2', self.error2)\n",
    "                \n",
    "                if abs(self.error2[-1]) > self.errorTolerance:\n",
    "                    numberOfAdjustmentsDuringIteration +=1\n",
    "                    self.backward()\n",
    "                    print('self.weightMatrices', self.weightMatrices)\n",
    "            self.errorForPlot.append(numberOfAdjustmentsDuringIteration)\n",
    "\n",
    "        print('Iterations: ', self.iterationNumber, '|Error|: ', self.error2[-1])\n",
    "        self.plotError()\n",
    "        \n",
    "    def plotError(self):\n",
    "        plt.plot()\n",
    "        plt.plot(np.arange(len(self.errorForPlot)), self.errorForPlot)\n",
    "        \n",
    "    def plot(self):\n",
    "        fig, (ax, ax2) = plt.subplots(1,2)\n",
    "        ax.plot(np.arange(len(self.outputForPlot1)), self.outputForPlot1)#, label='Input 1')\n",
    "        ax2.plot(np.arange(len(self.outputForPlot2)), self.outputForPlot2)#, label='Input 2')\n",
    "        ax.set_title('Input 1')\n",
    "        ax2.set_title('Input 22')\n",
    "        plt.savefig('simple.pdf')\n",
    "        \n",
    "    def differentiateActivationFunction(self, weightedInputs):\n",
    "        if isinstance(weightedInputs, np.ndarray):\n",
    "            if weightedInputs.ndim == 1:\n",
    "                onesArray = np.ones(len(weightedInputs))\n",
    "        else:\n",
    "            onesArray = 1\n",
    "        out = self.activationFunction(weightedInputs)*(onesArray - self.activationFunction(weightedInputs))\n",
    "        #print(self.activationFunction(weightedInputs), onesArray, out)\n",
    "        #print('out ', out)\n",
    "        return 1\n",
    "        #return out\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        weightedInputs = []\n",
    "        #print('self.inputs', self.inputs)\n",
    "        weightedInputs.append(self.weightMatrices[0] @ self.inputs)\n",
    "        self.outputs = []\n",
    "        self.outputs.append(self.activationFunction(weightedInputs[-1]))\n",
    "\n",
    "        for layer in range(1, len(self.nodeNumbers)-1):\n",
    "            outputsIncludingBias = np.concatenate([[1], self.outputs[-1]])\n",
    "            print('layer', layer)\n",
    "            print('self.weightMatrices[layer]', self.weightMatrices[layer])\n",
    "            print('outputsIncludingBias', outputsIncludingBias)\n",
    "            weightedInputs.append(self.weightMatrices[layer] @ outputsIncludingBias)\n",
    "            self.outputs.append(self.activationFunction(weightedInputs[-1]))\n",
    "        self.weightedInputs = weightedInputs\n",
    "        #print('self.outputs', self.outputs[-1])\n",
    "            \n",
    "    def calculateErrors(self):\n",
    "        self.error2 = 0\n",
    "        if not isinstance(self.targets, list):\n",
    "                self.error2 += (self.targets - self.outputs[-1])**2\n",
    "                #print('WRONG')\n",
    "        else:\n",
    "            for outputNodeNumber in range(len(self.outputs)):\n",
    "            #print('outputNodeNumber', outputNodeNumber)\n",
    "                self.error2 += (self.targets[outputNodeNumber] - \\\n",
    "                           self.outputs[-1][outputNodeNumber])**2\n",
    "        \n",
    "    def backward(self):\n",
    "        # Output deltas\n",
    "        self.deltaVectors = []\n",
    "        '''\n",
    "        deltaValuesOld = np.array([(self.outputs[-1][outputNumber] - self.targets[outputNumber])\\\n",
    "                      *self.differentiateActivationFunction(self.weightedInputs[-1][outputNumber]) \\\n",
    "                      for outputNumber in range(len(self.targets))])\n",
    "        '''\n",
    "        print('weightedInputs',self.weightedInputs)\n",
    "        deltaValues = (self.outputs[-1] - self.targets)* self.differentiateActivationFunction(self.weightedInputs[-1])\n",
    "        self.deltaVectors.append(deltaValues)\n",
    "        \n",
    "        # Hidden deltas\n",
    "        if not isinstance(self.targets, np.ndarray):\n",
    "            targetForLoop = np.array([self.targets])\n",
    "        for layerNumber in range(len(self.nodeNumbers)-2):\n",
    "            \n",
    "            deltaVecs = []\n",
    "            #for j in range(self.nodeNumbers[(layerNumber+1)+1]):\n",
    "            print('self.weightedInputs[-1]',self.weightedInputs[-1])\n",
    "            for j in range(2):\n",
    "                print('j', j)\n",
    "                deltaSum = 0\n",
    "                #print('self.targetLength',self.targetLength)\n",
    "                for k in range(len(self.targetLength)):\n",
    "                    deltaSum += self.deltaVectors[-1-layerNumber][k] * self.weightMatrices[-1][k,j+1] \n",
    "                deltaVecs.append(deltaSum*self.differentiateActivationFunction(self.weightedInputs[-1][j]))\n",
    "        self.deltaVectors.insert(0, deltaVecs)\n",
    "        \n",
    "        print('deltaVectors', self.deltaVectors)\n",
    "        \n",
    "        # Output weights\n",
    "        outputsIncludingBias = np.concatenate([[1], self.outputs[-2]])\n",
    "        for j in range(self.nodeNumbers[-2] + 1):\n",
    "            #print(self.targetLength)\n",
    "            for k in range(len(self.targetLength)):\n",
    "                self.weightMatrices[-1][k, j] -= \\\n",
    "                self.learningRate*self.deltaVectors[1][k]*outputsIncludingBias[j]\n",
    "        print('self.weightMatrices',self.weightMatrices)\n",
    "        # Hidden weights\n",
    "        print('self.weightMatrices[0]', self.weightMatrices[0])\n",
    "        print('self.deltaVectors[0]', self.deltaVectors[0])\n",
    "        print('self.inputs', self.inputs)\n",
    "        for inputNumber in range(self.nodeNumbers[0]+1):\n",
    "            for hiddenNodeNumber in range(self.nodeNumbers[1]): # fix indexes\n",
    "                print('inputNumber', inputNumber, 'hiddenNodeNumber', hiddenNodeNumber)\n",
    "                \n",
    "                self.weightMatrices[0][hiddenNodeNumber, inputNumber] -= self.learningRate \\\n",
    "                * self.deltaVectors[0][hiddenNodeNumber]*self.inputs[inputNumber]\n",
    "     \n",
    "#def activationFunction(x):\n",
    " #   return x\n",
    " \n",
    "\n",
    "def activationFunction(x):\n",
    "    return 1./(1+np.exp(-x))\n",
    " \n",
    "\n",
    "numberOfNodes = [2,2,1]\n",
    "activationFunction = activationFunction\n",
    "learningRate = 0.01\n",
    "targetMatrix = np.array(((0), (1), (1), (0))).T\n",
    "inputMatrix = np.array(((-1,0, 0), (-1, 0, 1), (-1,1, 0), (-1,1,1))).T\n",
    "errorTolerance = 1e-3\n",
    "maxIterations= 3\n",
    "test = False\n",
    "singleOutput = True\n",
    "\n",
    "nn=NN(numberOfNodes, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations, test)\n",
    "nn.runMultipleInput()\n",
    "'''\n",
    "print('nn.weightMatrices',nn.weightMatrices)\n",
    "\n",
    "nn.forward()\n",
    "print('nn.weightedInputs',nn.weightedInputs)\n",
    "print('nn.outputs',nn.outputs)\n",
    "\n",
    "nn.calculateErrors()\n",
    "print('nn.error2',nn.error2)\n",
    "\n",
    "nn.backward()\n",
    "print('nn.deltaVectors',nn.deltaVectors)\n",
    "print('weightMatrices', nn.weightMatrices)\n",
    "\n",
    "nn.run()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.weightMatrices [array([[ 0.10056474, -0.1719194 ,  0.35276571],\n",
      "       [-0.11213153,  0.18424533,  0.15482363]]), array([[-0.47468402,  0.41125376,  0.09126854],\n",
      "       [ 0.04850915, -0.35575858,  0.17112902]])]\n",
      "nn2.inputs [1, 0, 1]\n",
      "nn.weightMatrices [array([[ 0.10056474, -0.1719194 ,  0.35276571],\n",
      "       [-0.11213153,  0.18424533,  0.15482363]]), array([[-0.47468402,  0.41125376,  0.09126854],\n",
      "       [ 0.04850915, -0.35575858,  0.17112902]])]\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.47468402  0.41125376  0.09126854]\n",
      " [ 0.04850915 -0.35575858  0.17112902]]\n",
      "outputsIncludingBias [1.         0.45333045 0.04269211]\n",
      "nn.weightedInputs [array([0.45333045, 0.04269211]), array([-0.28435372, -0.10546119])]\n",
      "nn.outputs [array([0.45333045, 0.04269211]), array([-0.28435372, -0.10546119])]\n",
      "nn.error2 1.6606865347708524\n",
      "weightedInputs [array([0.45333045, 0.04269211]), array([-0.28435372, -0.10546119])]\n",
      "self.weightedInputs[-1] [-0.28435372 -0.10546119]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[-0.06885265263643345, -0.005236271258762155], array([0.46905979, 0.01229501])]\n",
      "self.weightMatrices [array([[ 0.10056474, -0.1719194 ,  0.35276571],\n",
      "       [-0.11213153,  0.18424533,  0.15482363]]), array([[-0.52159   ,  0.38998985,  0.08926603],\n",
      "       [ 0.04727965, -0.35631595,  0.17107653]])]\n",
      "self.weightMatrices[0] [[ 0.10056474 -0.1719194   0.35276571]\n",
      " [-0.11213153  0.18424533  0.15482363]]\n",
      "self.deltaVectors[0] [-0.06885265263643345, -0.005236271258762155]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "nn.deltaVectors [[-0.06885265263643345, -0.005236271258762155], array([0.46905979, 0.01229501])]\n",
      "weightMatrices [array([[ 0.10745001, -0.1719194 ,  0.35965098],\n",
      "       [-0.1116079 ,  0.18424533,  0.15534726]]), array([[-0.52159   ,  0.38998985,  0.08926603],\n",
      "       [ 0.04727965, -0.35631595,  0.17107653]])]\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.52159     0.38998985  0.08926603]\n",
      " [ 0.04727965 -0.35631595  0.17107653]]\n",
      "outputsIncludingBias [1.         0.46710098 0.04373936]\n",
      "weightedInputs [array([0.46710098, 0.04373936]), array([-0.33552091, -0.11167311])]\n",
      "self.weightedInputs[-1] [-0.33552091 -0.11167311]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[-0.10236552049582266, -0.006926258143444891], array([0.59844051, 0.01386354])]\n",
      "self.weightMatrices [array([[ 0.10745001, -0.1719194 ,  0.35965098],\n",
      "       [-0.1116079 ,  0.18424533,  0.15534726]]), array([[-0.58143405,  0.36203663,  0.08664849],\n",
      "       [ 0.04589329, -0.35696352,  0.17101589]])]\n",
      "self.weightMatrices[0] [[ 0.10745001 -0.1719194   0.35965098]\n",
      " [-0.1116079   0.18424533  0.15534726]]\n",
      "self.deltaVectors[0] [-0.10236552049582266, -0.006926258143444891]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.58143405  0.36203663  0.08664849]\n",
      " [ 0.04589329 -0.35696352  0.17101589]]\n",
      "outputsIncludingBias [1.         0.48757409 0.04512461]\n",
      "weightedInputs [array([0.48757409, 0.04512461]), array([-0.40100438, -0.12043584])]\n",
      "self.weightedInputs[-1] [-0.40100438 -0.12043584]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[-0.15683265891971926, -0.009578091633909118], array([0.78709673, 0.01625169])]\n",
      "self.weightMatrices [array([[ 0.11768656, -0.1719194 ,  0.36988753],\n",
      "       [-0.11091528,  0.18424533,  0.15603989]]), array([[-0.66014372,  0.32365984,  0.08309674],\n",
      "       [ 0.04426812, -0.35775591,  0.17094256]])]\n",
      "self.weightMatrices[0] [[ 0.11768656 -0.1719194   0.36988753]\n",
      " [-0.11091528  0.18424533  0.15603989]]\n",
      "self.deltaVectors[0] [-0.15683265891971926, -0.009578091633909118]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.66014372  0.32365984  0.08309674]\n",
      " [ 0.04426812 -0.35775591  0.17094256]]\n",
      "outputsIncludingBias [1.         0.51894062 0.04704023]\n",
      "weightedInputs [array([0.51894062, 0.04704023]), array([-0.48827459, -0.13334477])]\n",
      "self.weightedInputs[-1] [-0.48827459 -0.13334477]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[-0.24913122638187632, -0.014102240755806916], array([1.08150931, 0.02015181])]\n",
      "self.weightMatrices [array([[ 0.13336983, -0.1719194 ,  0.38557079],\n",
      "       [-0.10995747,  0.18424533,  0.1569977 ]]), array([[-0.76829465,  0.26753593,  0.0780093 ],\n",
      "       [ 0.04225294, -0.35880167,  0.17084776]])]\n",
      "self.weightMatrices[0] [[ 0.13336983 -0.1719194   0.38557079]\n",
      " [-0.10995747  0.18424533  0.1569977 ]]\n",
      "self.deltaVectors[0] [-0.24913122638187632, -0.014102240755806916]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.76829465  0.26753593  0.0780093 ]\n",
      " [ 0.04225294 -0.35880167  0.17084776]]\n",
      "outputsIncludingBias [1.         0.56876687 0.04986068]\n",
      "weightedInputs [array([0.56876687, 0.04986068]), array([-0.61223948, -0.15330297])]\n",
      "self.weightedInputs[-1] [-0.61223948 -0.15330297]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[-0.41065600250584283, -0.02276805002892974], array([1.59140398, 0.0271047 ])]\n",
      "self.weightMatrices [array([[ 0.15828295, -0.1719194 ,  0.41048392],\n",
      "       [-0.10854724,  0.18424533,  0.15840792]]), array([[-0.92743505,  0.17702214,  0.07007445],\n",
      "       [ 0.03954247, -0.36034329,  0.17071262]])]\n",
      "self.weightMatrices[0] [[ 0.15828295 -0.1719194   0.41048392]\n",
      " [-0.10854724  0.18424533  0.15840792]]\n",
      "self.deltaVectors[0] [-0.41065600250584283, -0.02276805002892974]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-0.92743505  0.17702214  0.07007445]\n",
      " [ 0.03954247 -0.36034329  0.17071262]]\n",
      "outputsIncludingBias [1.         0.65089807 0.05441429]\n",
      "weightedInputs [array([0.65089807, 0.05441429]), array([-0.80839863, -0.18571507])]\n",
      "self.weightedInputs[-1] [-0.80839863 -0.18571507]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[-0.6626223666697322, -0.042331784922836346], array([2.64371056, 0.04089542])]\n",
      "self.weightMatrices [array([[ 0.19934855, -0.1719194 ,  0.45154952],\n",
      "       [-0.10627044,  0.18424533,  0.16068473]]), array([[-1.19180611,  0.00494353,  0.05568889],\n",
      "       [ 0.03545293, -0.36300517,  0.17049009]])]\n",
      "self.weightMatrices[0] [[ 0.19934855 -0.1719194   0.45154952]\n",
      " [-0.10627044  0.18424533  0.16068473]]\n",
      "self.deltaVectors[0] [-0.6626223666697322, -0.042331784922836346]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-1.19180611  0.00494353  0.05568889]\n",
      " [ 0.03545293 -0.36300517  0.17049009]]\n",
      "outputsIncludingBias [1.         0.78342254 0.06288065]\n",
      "weightedInputs [array([0.78342254, 0.06288065]), array([-1.18443148, -0.23821297])]\n",
      "self.weightedInputs[-1] [-1.18443148 -0.23821297]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[-0.006297645502564005, -0.09636927694805793], array([5.65180011, 0.07026292])]\n",
      "self.weightMatrices [array([[ 0.26561079, -0.1719194 ,  0.51781175],\n",
      "       [-0.10203726,  0.18424533,  0.1649179 ]]), array([[-1.75698612, -0.43783123,  0.02015   ],\n",
      "       [ 0.02842664, -0.36850972,  0.17004827]])]\n",
      "self.weightMatrices[0] [[ 0.26561079 -0.1719194   0.51781175]\n",
      " [-0.10203726  0.18424533  0.1649179 ]]\n",
      "self.deltaVectors[0] [-0.006297645502564005, -0.09636927694805793]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-1.75698612 -0.43783123  0.02015   ]\n",
      " [ 0.02842664 -0.36850972  0.17004827]]\n",
      "outputsIncludingBias [1.         0.78468207 0.0821545 ]\n",
      "weightedInputs [array([0.78468207, 0.0821545 ]), array([-2.09888902, -0.2467661 ])]\n",
      "self.weightedInputs[-1] [-2.09888902 -0.2467661 ]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[57.580894161858104, -0.128925038254819], array([20.15586866,  0.07591996])]\n",
      "self.weightMatrices [array([[ 0.26624055, -0.1719194 ,  0.51844152],\n",
      "       [-0.09240033,  0.18424533,  0.17455483]]), array([[-3.77257298, -2.0194261 , -0.14543953],\n",
      "       [ 0.02083464, -0.37446703,  0.16942455]])]\n",
      "self.weightMatrices[0] [[ 0.26624055 -0.1719194   0.51844152]\n",
      " [-0.09240033  0.18424533  0.17455483]]\n",
      "self.deltaVectors[0] [57.580894161858104, -0.128925038254819]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-3.77257298 -2.0194261  -0.14543953]\n",
      " [ 0.02083464 -0.37446703  0.16942455]]\n",
      "outputsIncludingBias [  1.         -10.73149676   0.10793951]\n",
      "weightedInputs [array([-10.73149676,   0.10793951]), array([17.88319298,  4.05771392])]\n",
      "self.weightedInputs[-1] [17.88319298  4.05771392]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[-3113698.082124059, -9092.625258306925], array([-5097.46476747,   -50.3453888 ])]\n",
      "self.weightMatrices [array([[-5.49184887, -0.1719194 , -5.2396479 ],\n",
      "       [-0.07950783,  0.18424533,  0.18744734]]), array([[ 5.05973904e+02, -5.47236209e+03,  5.48763446e+01],\n",
      "       [ 5.05537352e+00, -5.44026047e+01,  7.12850203e-01]])]\n",
      "self.weightMatrices[0] [[-5.49184887 -0.1719194  -5.2396479 ]\n",
      " [-0.07950783  0.18424533  0.18744734]]\n",
      "self.deltaVectors[0] [-3113698.082124059, -9092.625258306925]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[ 5.05973904e+02 -5.47236209e+03  5.48763446e+01]\n",
      " [ 5.05537352e+00 -5.44026047e+01  7.12850203e-01]]\n",
      "outputsIncludingBias [1.00000000e+00 6.22728885e+05 1.81863299e+03]\n",
      "weightedInputs [array([622728.88492805,   1818.63299117]), array([-3.40769764e+09, -3.38767719e+07])]\n",
      "self.weightedInputs[-1] [-3.40769764e+09 -3.38767719e+07]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[2.5146647632010025e+51, -2.492139751563264e+45], array([3.95715589e+28, 3.88781931e+22])]\n",
      "self.weightMatrices [array([[ 3.11364316e+05, -1.71919401e-01,  3.11364569e+05],\n",
      "       [ 9.09183018e+02,  1.84245331e-01,  9.09449973e+02]]), array([[-3.95715589e+27, -2.46423528e+33, -7.19661426e+30],\n",
      "       [-3.88781931e+21, -2.42105739e+27, -7.07051647e+24]])]\n",
      "self.weightMatrices[0] [[ 3.11364316e+05 -1.71919401e-01  3.11364569e+05]\n",
      " [ 9.09183018e+02  1.84245331e-01  9.09449973e+02]]\n",
      "self.deltaVectors[0] [2.5146647632010025e+51, -2.492139751563264e+45]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[-3.95715589e+27 -2.46423528e+33 -7.19661426e+30]\n",
      " [-3.88781931e+21 -2.42105739e+27 -7.07051647e+24]]\n",
      "outputsIncludingBias [ 1.00000000e+00 -5.02932953e+50  4.98427950e+44]\n",
      "weightedInputs [array([-5.02932953e+50,  4.98427950e+44]), array([1.23934512e+84, 1.21762954e+78])]\n",
      "self.weightedInputs[-1] [1.23934512e+84 1.21762954e+78]\n",
      "j 0\n",
      "j 1\n",
      "deltaVectors [[-inf, -inf], array([-1.90360477e+252, -1.80528396e+234])]\n",
      "self.weightMatrices [array([[-2.51466476e+50, -1.71919401e-01, -2.51466476e+50],\n",
      "       [ 2.49213975e+44,  1.84245331e-01,  2.49213975e+44]]), array([[ 1.90360477e+251, -9.57385566e+301,  9.48809822e+295],\n",
      "       [ 1.80528396e+233, -9.07936792e+283,  8.99803983e+277]])]\n",
      "self.weightMatrices[0] [[-2.51466476e+50 -1.71919401e-01 -2.51466476e+50]\n",
      " [ 2.49213975e+44  1.84245331e-01  2.49213975e+44]]\n",
      "self.deltaVectors[0] [-inf, -inf]\n",
      "self.inputs [1, 0, 1]\n",
      "inputNumber 0 hiddenNodeNumber 0\n",
      "inputNumber 0 hiddenNodeNumber 1\n",
      "inputNumber 1 hiddenNodeNumber 0\n",
      "inputNumber 1 hiddenNodeNumber 1\n",
      "inputNumber 2 hiddenNodeNumber 0\n",
      "inputNumber 2 hiddenNodeNumber 1\n",
      "layer 1\n",
      "self.weightMatrices[layer] [[ 1.90360477e+251 -9.57385566e+301  9.48809822e+295]\n",
      " [ 1.80528396e+233 -9.07936792e+283  8.99803983e+277]]\n",
      "outputsIncludingBias [ 1. nan nan]\n",
      "Iterations:  11 |Error|:  nan Output:  [nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/ipykernel_launcher.py:164: RuntimeWarning: overflow encountered in double_scalars\n",
      "/home/k/.local/lib/python3.6/site-packages/ipykernel_launcher.py:184: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "## Slides. Must change derivative inside class to 1\n",
    "def activationFunction(x):\n",
    "    return x\n",
    "\n",
    "numberOfNodes,  activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations = \\\n",
    "[2,2,2], activationFunction, 0.1, np.array([1, 0]), np.array((1, 0, 1)), 1e-6, 100\n",
    "test = True\n",
    "\n",
    "\n",
    "nn2=NN(numberOfNodes, activationFunction, learningRate, targetMatrix, inputMatrix, errorTolerance, maxIterations, test=False)\n",
    "\n",
    "\n",
    "print('nn2.inputs',nn2.inputs)\n",
    "\n",
    "print('nn.weightMatrices',nn2.weightMatrices)\n",
    "\n",
    "nn2.forward()\n",
    "\n",
    "print('nn.weightedInputs',nn2.weightedInputs)\n",
    "print('nn.outputs',nn2.outputs)\n",
    "\n",
    "nn2.calculateErrors()\n",
    "print('nn.error2',nn2.error2)\n",
    "\n",
    "nn2.backward()\n",
    "print('nn.deltaVectors',nn2.deltaVectors)\n",
    "print('weightMatrices', nn2.weightMatrices)\n",
    "\n",
    "nn2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  100000 |Error|:  5.3734953521503506e-05 Output:  [0.99481832 0.00518509]\n"
     ]
    }
   ],
   "source": [
    "def activationFunction(x):\n",
    "    return 1./(1+np.exp(-x)) \n",
    "\n",
    "numberOfNodes,  activationFunction, learningRate, targets, inputs, errorTolerance, maxIterations = \\\n",
    "[2,2,2], activationFunction, 0.1, np.array([1, 0]), np.array((1, 0, 1)), 1e-6, 100000\n",
    "inputs = np.array((1, 0, 1))\n",
    "\n",
    "nn3=NN(numberOfNodes, activationFunction, learningRate, targets, inputs, errorTolerance, maxIterations, test=False)\n",
    "nn3.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the lecture slides the backpropagation deltas are first presented as $\\delta_k = (y_k − t_k )y_k (1 − y_k )$. What does this tell us about the activation function in use?\n",
    "\n",
    "The Sigmoid function is used as activation function. We have $\\delta_k = (y_k -t_k) f'(a)$, where $a$ is the input to the acitivation functino in the output layer. When the Sigmoid is used we have $f'(a_k) = sigmoid(a_k) (1 - sigmoid(a_k)) = y_k(1-y_k)$, which is what we have.\n",
    "\n",
    "# You are to design an MLP that would learn to hyphenate words correctly. You would have a dictionary that shows correct hyphenation examples for lots of words. Think about the following: \n",
    "\n",
    "## What should the input to the neural net be?\n",
    "Traning face: The full words without hypenation as input and the correct words from the dictionary.\n",
    "Else: Full words without hypenation.\n",
    "\n",
    "<mark> Sol:Input = 2 letters.?? So not words?<mark>\n",
    "\n",
    "## How should this input be encoded to work well with the classifier?\n",
    "NN needs numbers. One interger per letter.\n",
    "\n",
    "## How is should the output be encoded?\n",
    "True and False --> 1d output. True = hyphenate.\n",
    "\n",
    "## How many layers do you need?\n",
    "Don' know. Suspect it is not a linear separable problem, so 1 hidden layer as a minimum.\n",
    "\n",
    "## How many neurons should there be in each layer?\n",
    "Experiment. Sol: Start with 2N/3, N = inputnumber, in 1st hidden, and N/3 sedond. <mark> Where does this come from?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
