{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "We start by giving a simple overview of the implementation. Then we will show the necessary vode for applying the NN-class made and the resulting results.\n",
    "\n",
    "## Performance measure\n",
    "The model performance is calculated by the accuracy of the estimated model when applied to the test data. The accuracy is the number of correct predictions divided by the number of total observations. <br>\n",
    "\n",
    "The model output is not on binary form. In order to calculate the accuracy, we transform the model output to binary form by use of the Hard max function. The Hard max function sets the largest element value in the putput vectors equal to one and the other elements to zero. \n",
    "\n",
    "## The main algorithm\n",
    "We will apply the method \"solAlg1\" from the Neural Network class \"nnClass.py\". The algorithm goes forward and backward for each observation. Before every epoch the order of the training observations is shuffled. \n",
    "\n",
    "## Early stopping\n",
    "The main algorithm \"solAlg1\" contains early stopping. The algorithm will run for a chosen number of epochs before the model performance on the validation set is calculated. When the validation set accuracy drops, we stop the training.\n",
    "\n",
    "## The main algorithm pseudo code\n",
    "Here follows pseudo code of the main algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solAlg1:\n",
    "        \n",
    "            for trainingCycle in range(trainingCyclesPerValidation):\n",
    "                shuffle index\n",
    "                for idx in range(np.shape(self.targetMatrixTrain)[0]):\n",
    "                    forward\n",
    "                    backward\n",
    "            calculate validation set performance\n",
    "            \n",
    "            if performance lower than best performance\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "The code is found in two files: <br>\n",
    "1) nnClassRevised.py: contains the Neural network solver class. <br>\n",
    "2) runAssignment2Revised.py:  contains a function for loading of the assignment data and functions for solving the specific tasks. <br>\n",
    "\n",
    "We start by importing everything from the above mentioned  files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnClassRevised import *\n",
    "from runAssignment2Revised import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"dataAssignment2Revised\", which is part of spyderTesting, split the data into training/velidation/test with the corresponding relations 50/25/25 per cent. We will first use this data split when analysing the model performance. By calling the function \"dataAssignment2Revised\", we load the data for the assignment and split it into test, validation and training sets. \"dataAssignment2Revised\" is almost identical to the file \"movements.py\" provided with the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targets, valid, valid_targets, test, test_targets = dataAssignment2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden nodes. Fixed validation set.\n",
    "In order to determine the optimal number of hidden nodes, we run the neural network with different number of nodes and study the model performance on validation sets. The solution algorith above is applied. In addition to the main part of the solution algorithm, the algorithm produces confusion matrices and accuracy scores. The implementation and results for different number of hidden nodes now follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hidden nodes:  6\n",
      "Activation function:  sigmoid\n",
      "Hidden nodes:  6\n",
      "Epochs per validation:  5\n",
      "Best Confusion Matrix: \n",
      " [[0.92 0.   0.   0.   0.08 0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.07 0.21 0.29 0.14 0.   0.14 0.14]\n",
      " [0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.08 0.   0.   0.08 0.83 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.21 0.11 0.68 0.  ]\n",
      " [0.12 0.   0.   0.   0.   0.   0.   0.88]]\n",
      "Best accuracy: 0.83\n",
      "TotalNumberOfIterations:  105\n",
      "Validations:  21\n",
      "\n",
      "Hidden nodes:  8\n",
      "Activation function:  sigmoid\n",
      "Hidden nodes:  8\n",
      "Epochs per validation:  5\n",
      "Best Confusion Matrix: \n",
      " [[0.92 0.   0.   0.   0.   0.   0.   0.08]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.92 0.   0.   0.   0.   0.08]\n",
      " [0.   0.   0.   0.57 0.   0.   0.14 0.29]\n",
      " [0.   0.   0.   0.06 0.94 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   1.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.16 0.11 0.74 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "Best accuracy: 0.89\n",
      "TotalNumberOfIterations:  135\n",
      "Validations:  27\n",
      "\n",
      "Hidden nodes:  12\n",
      "Activation function:  sigmoid\n",
      "Hidden nodes:  12\n",
      "Epochs per validation:  5\n",
      "Best Confusion Matrix: \n",
      " [[0.92 0.   0.08 0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.07 0.36 0.5  0.   0.   0.   0.07]\n",
      " [0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.92 0.08 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   1.   0.  ]\n",
      " [0.06 0.   0.06 0.   0.   0.   0.   0.88]]\n",
      "Best accuracy: 0.90\n",
      "TotalNumberOfIterations:  100\n",
      "Validations:  20\n"
     ]
    }
   ],
   "source": [
    "activationFunction= 'sigmoid'\n",
    "trainingCyclesPerValidation = 5\n",
    "maxValidations= 300\n",
    "maxLocalOptima = 15\n",
    "np.random.seed(1)\n",
    "\n",
    "for numberOfHiddenNodes in 6, 8 ,12:\n",
    "    fixedValidationSet( train=train,\n",
    "                       train_targets = train_targets,\n",
    "                       valid=valid,\n",
    "                       valid_targets=valid_targets,\n",
    "                       numberOfHiddenNodes = numberOfHiddenNodes,\n",
    "                        activationFunction = activationFunction,\n",
    "                        trainingCyclesPerValidation = trainingCyclesPerValidation,\n",
    "                        maxValidations = maxValidations,\n",
    "                        maxLocalOptima = maxLocalOptima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Warning:__ The results change with new runs due to the randomness in the main algorithm. Hence re-running the above code will give different results, especially wrt. the confusion matrix and which classes are worst.<br>\n",
    "\n",
    "We see that the accuracy lays between 83 and 90 percent, depending on the number of hidden nodes. <br>\n",
    "\n",
    "The performance increaess with number of hidden nodes. 12 hidden nodes gives 90 percent accuracy on validation.<br>\n",
    "\n",
    "The number of simulations seems to be about the same irrespective of node numbers. This is a bit surprising, since I would expect a more complex network needing more simulations. <br>\n",
    "\n",
    "There are four classes that has mis-classifications in the case of 12 nodes. 12 per cent is the largest error. <br>\n",
    "\n",
    "The mis-classfication pattern differst between the different node numbers.\n",
    "\n",
    "# K-fold\n",
    "Next we will apply the K-fold crossvalidation method, which is a resempling method. All the data is divided into $K$ number of folds. For one iteration one of the folds performs as validation set while the remaining folds perform as training set. <br>\n",
    "\n",
    "K-fold is implemented as an own method in the NN-class. The traning, testing and  validation sets are concatenated to one data set. The resulting data set is then divided into $K$ folds. Each combination of folds are sent into the main solution algorithm descirbed and applied above. Hence we will get $K$ number of results from the $K$-fold analysis.<br>\n",
    "\n",
    "In order to compare the K-fold method with the fixed validation set method, we choose the same number of epochs per validation and the same limit for worsening solutions. Furthermore we choose $K=3$ so that the size of the training and validation sets mimimcs the size from the previous analysis with fixed training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#####################    Hidden nodes:  6    ############################\n",
      "\n",
      "Best accuracy folds:  [0.8067331670822944, 0.835, 0.7196495619524406]\n",
      "Mean(bestScores): 0.79, std(bestScores) 0.05\n",
      "\n",
      "#####################    Hidden nodes:  8    ############################\n",
      "\n",
      "Best accuracy folds:  [0.9364089775561097, 0.805243445692884, 0.87375]\n",
      "Mean(bestScores): 0.87, std(bestScores) 0.05\n",
      "\n",
      "#####################    Hidden nodes:  12    ############################\n",
      "\n",
      "Best accuracy folds:  [0.98, 0.8915211970074813, 0.9011264080100124]\n",
      "Mean(bestScores): 0.92, std(bestScores) 0.04\n"
     ]
    }
   ],
   "source": [
    "for numberOfHiddenNodes in 6, 8 ,12:\n",
    "    print('\\n#####################   ', 'Hidden nodes: ', numberOfHiddenNodes, '   ############################')\n",
    "    runKfold(train=train ,\n",
    "            train_targets=train_targets,\n",
    "            valid=valid ,\n",
    "            valid_targets=valid_targets ,\n",
    "            \n",
    "            numberOfHiddenNodes=numberOfHiddenNodes,\n",
    "            activationFunction= 'sigmoid',\n",
    "            numberOfFolds = 3, \n",
    "            trainingCyclesPerValidation=5,\n",
    "            maxValidations = 1000,\n",
    "            maxLocalOptima = 15,\n",
    "            printConfusionMatrix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy scores lay in the same area as for the static train/test split, the mean scores being between approximately 80 and 90 per cent. The rankings between the different hidden node numbers are the same as for the static train/test split: the highest node number is still the best, and the lowest node number is now the worst. <br>\n",
    "\n",
    "The standard deviations gives extra information about the uncertainty of the different scores. We see that the standard deviations are of such order that the confidence intervals do not overlap. Hence the difference in performance between the node numbers seems significant. <br>\n",
    "\n",
    "\n",
    "# Testing the model\n",
    "Til now we have studied the optimal number of hidden nodes. Let's see how our model performs on the test set. We apply the highest number of layers, which performed best both with K-fold crossvalidation and with the static train/validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hidden nodes:  12\n",
      "Activation function:  sigmoid\n",
      "Hidden nodes:  12\n",
      "Epochs per validation:  5\n",
      "Best Confusion Matrix: \n",
      " [[0.85 0.   0.08 0.   0.   0.   0.   0.08]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.07 0.29 0.36 0.07 0.   0.07 0.14]\n",
      " [0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   1.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.05 0.05 0.89 0.  ]\n",
      " [0.   0.06 0.   0.   0.   0.   0.   0.94]]\n",
      "Best accuracy: 0.88\n",
      "TotalNumberOfIterations:  110\n",
      "Validations:  22\n",
      "\n",
      "Test Confusion Matrix: \n",
      " [[1.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.08 0.15 0.15 0.31 0.   0.   0.31]\n",
      " [0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.07 0.73 0.2  0.  ]\n",
      " [0.   0.11 0.   0.   0.22 0.11 0.56 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "Best accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "activationFunction= 'sigmoid'\n",
    "trainingCyclesPerValidation = 5\n",
    "maxValidations= 300\n",
    "maxLocalOptima = 15\n",
    "numberOfHiddenNodes = 12\n",
    "\n",
    "runTestSet(train=train,\n",
    "           train_targets = train_targets,\n",
    "           valid=valid,\n",
    "           valid_targets=valid_targets,\n",
    "           test=test,\n",
    "           test_targets=test_targets,\n",
    "           numberOfHiddenNodes = numberOfHiddenNodes,\n",
    "           activationFunction = activationFunction,\n",
    "           trainingCyclesPerValidation = trainingCyclesPerValidation,\n",
    "           maxValidations = maxValidations,\n",
    "           maxLocalOptima = maxLocalOptima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy drops from 88 per cent on the validation data to 83 per cent on the test data. The accuracy drop is not surprising. The number of hidden nodes are optimized for the validation data and not for the test data. The largest difference between the validation and test predictions is on class 1, which drops from 94 per cent to 44 per cent when going from validation to test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
