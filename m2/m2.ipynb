{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "We start by giving a simple overview of the implementation. Then we will show the necessary vode for applying the NN-class made and the resulting results.\n",
    "\n",
    "## Performance measure\n",
    "The model performance is calculated by the accuracy of the estimated model when applied to the validation data. The accuracy is the number of correct predictions divided by the number of total observations. <br>\n",
    "\n",
    "The model output is not on binary form. In order to calculate the accuracy, we transform the model output to binary form by use of the Hard max function. The Hard max function sets the largest element value in the putput vectors equal to one and the other elements to zero. \n",
    "\n",
    "## The main algorithm\n",
    "We will apply the method \"solAlg1\" from the Neural Network class \"nnClass.py\". The algorithm goes forward and backward for each observation. Before every epoch the order of the training observations is shuffled. \n",
    "\n",
    "## Early stopping\n",
    "The main algorithm \"solAlg1\" contains early stopping. The algorithm will run for a chosen number of epochs before the model performance on the validation set is calculated. When the solution has not improved in a user given number of periods, this is a sign of the network having found the global optimum, and the simulations end. We allow the validation set performance to drop for several runs in order to less easily get trapped in local optima.\n",
    "\n",
    "## The main algorithm pseudo code\n",
    "Here follows pseudo code of the main algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solAlg1:\n",
    "        \n",
    "        while localOptima < maxLocalOptima and number of validations < maxValidations:\n",
    "            for trainingCycle in range(trainingCyclesPerValidation):\n",
    "                shuffle index\n",
    "                for idx in range(np.shape(self.targetMatrixTrain)[0]):\n",
    "                    forward\n",
    "                    backward\n",
    "            calculate validation set performance\n",
    "            \n",
    "            if performance lower than best performance\n",
    "                localOptima += 1\n",
    "            else:\n",
    "                store new performance score\n",
    "            validationIdx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "The code is found in two files: <br>\n",
    "1) nnClass.py: contains the Neural network solver class. <br>\n",
    "2) runAssignment2.py:  contains a function for loading of the assignment data and functions for solving the specific tasks. <br>\n",
    "\n",
    "We start by importing everything from the above mentioned  files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnClass import *\n",
    "from runAssignment2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"dataAssignment2\", which is part of spyerTesting, split the data into training/velidation/test with the corresponding relations 50/25/25 per cent. We will first use this data split when analysing the model performance. By calling the function \"dataAssignment2\", we load the data for the assignment and split it into test, validation and training sets. \"dataAssignment2\" is almost identical to the file \"movements.py\" provided with the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targets, valid, valid_targets, test, test_targets = dataAssignment2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden nodes. Fixed validation set.\n",
    "In order to determine the optimal number of hidden nodes, we run the neural network with different number of nodes and study the model performance on validation sets. The solution algorith above is applied. In addition to the main part of the solution algorithm, the algorithm produces confusion matrices and accuracy scores. The implementation and results for different number of hidden nodes now follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hidden nodes:  6\n",
      "Activation function:  sigmoid\n",
      "Hidden nodes:  6\n",
      "Epochs per validation:  5\n",
      "Best Confusion Matrix: \n",
      " [[0.67 0.   0.   0.   0.33 0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.26 0.   0.26 0.37 0.   0.   0.11]\n",
      " [0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.07 0.   0.   0.14 0.71 0.07 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   1.   0.  ]\n",
      " [0.06 0.   0.06 0.   0.   0.   0.   0.89]]\n",
      "Best accuracy: 0.82\n",
      "TotalNumberOfIterations:  160\n",
      "Validations:  32\n",
      "\n",
      "Hidden nodes:  8\n",
      "Activation function:  sigmoid\n",
      "Hidden nodes:  8\n",
      "Epochs per validation:  5\n",
      "Best Confusion Matrix: \n",
      " [[0.94 0.   0.06 0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.79 0.   0.   0.   0.21]\n",
      " [0.   0.   0.   0.18 0.82 0.   0.   0.  ]\n",
      " [0.   0.07 0.   0.   0.   0.93 0.   0.  ]\n",
      " [0.   0.   0.07 0.   0.   0.   0.93 0.  ]\n",
      " [0.   0.   0.   0.17 0.   0.   0.   0.83]]\n",
      "Best accuracy: 0.91\n",
      "TotalNumberOfIterations:  140\n",
      "Validations:  28\n",
      "\n",
      "Hidden nodes:  12\n",
      "Activation function:  sigmoid\n",
      "Hidden nodes:  12\n",
      "Epochs per validation:  5\n",
      "Best Confusion Matrix: \n",
      " [[0.89 0.   0.06 0.   0.   0.   0.   0.06]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.05 0.11 0.58 0.05 0.   0.05 0.16]\n",
      " [0.   0.   0.   0.09 0.91 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.07 0.93 0.   0.  ]\n",
      " [0.   0.   0.07 0.   0.   0.   0.93 0.  ]\n",
      " [0.   0.   0.   0.06 0.   0.   0.   0.94]]\n",
      "Best accuracy: 0.90\n",
      "TotalNumberOfIterations:  105\n",
      "Validations:  21\n"
     ]
    }
   ],
   "source": [
    "activationFunction= 'sigmoid'\n",
    "trainingCyclesPerValidation = 5\n",
    "maxValidations= 300\n",
    "maxLocalOptima = 15\n",
    "\n",
    "for numberOfHiddenNodes in 6, 8 ,12:\n",
    "    fixedValidationSet( train=train,\n",
    "                       train_targets = train_targets,\n",
    "                       valid=valid,\n",
    "                       valid_targets=valid_targets,\n",
    "                       numberOfHiddenNodes = numberOfHiddenNodes,\n",
    "                        activationFunction = activationFunction,\n",
    "                        trainingCyclesPerValidation = trainingCyclesPerValidation,\n",
    "                        maxValidations = maxValidations,\n",
    "                        maxLocalOptima = maxLocalOptima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Warning:__ The results change with new runs due to the randomness in the main algorithm. Hence re-running the above code will give different results, especially wrt. the confusion matrix and which classes are worst.<br>\n",
    "\n",
    "We see that the accuracy lays between 85 and 93 percent, depending on the number of hidden nodes. <br>\n",
    "\n",
    "There is not a linear relation between number of nodes and model performance. The middle node number does best. However, we must take into account the randomness of the algorithm. The training observations are shuffled between each epcoh. Hence the performance will never stay the same for one solution, and the above results are just a suggestion. In order to study the optimal node number further, we could have solved for each node number many times and used average performance. <br>\n",
    "\n",
    "The number of simulations seems to be about the same irrespective of node numbers. This is a bit surprising, since I would expect a more complex network needing more simulations. <br>\n",
    "\n",
    "Based on the above, which is uncertain, it looks like 8 nodes is the best of the provided alternatives. There are five classes that has mis-classifications in the case of 8 nodes. The classes with mis-classifications are classes 3-7. Clas 6 is worst, since it has the lowest share of correct classifications. <br>\n",
    "\n",
    "The mis-classfication pattern differst between the different node numbers.\n",
    "\n",
    "# K-fold\n",
    "Next we will apply the K-fold crossvalidation method, which is a resempling method. All the data excluding the test data is divided into $K$ number of folds. For one iteration one of the folds performs as validation set while the remaining folds perform as training set. <br>\n",
    "\n",
    "K-fold is implemented as an own method in the NN-class. The traning and validation sets are concatenated to one data set. The resulting data set is then divided into $K$ folds. Each combination of folds are sent into the main solution algorithm descirbed and applied above. Hence we will get $K$ number of results from the $K$-fold analysis.<br>\n",
    "\n",
    "In order to compare the K-fold method with the fixed validation set method, we choose the same number of epochs per validation and the same limit for worsening solutions. Furthermore we choose $K=3$ so that the size of the training and validation sets mimimcs the size from the previous analysis with fixed training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#####################    Hidden nodes:  6    ############################\n",
      "\n",
      "Best accuracy folds:  [0.8700000000000001, 0.8623279098873592, 0.7825]\n",
      "Mean(bestScores): 0.84, std(bestScores) 0.04\n",
      "\n",
      "#####################    Hidden nodes:  8    ############################\n",
      "\n",
      "Best accuracy folds:  [0.9199999999999999, 0.8826466916354557, 0.8377028714107365]\n",
      "Mean(bestScores): 0.88, std(bestScores) 0.03\n",
      "\n",
      "#####################    Hidden nodes:  12    ############################\n",
      "\n",
      "Best accuracy folds:  [0.8998748435544429, 0.8987499999999999, 0.9025000000000001]\n",
      "Mean(bestScores): 0.90, std(bestScores) 0.00\n"
     ]
    }
   ],
   "source": [
    "for numberOfHiddenNodes in 6, 8 ,12:\n",
    "    print('\\n#####################   ', 'Hidden nodes: ', numberOfHiddenNodes, '   ############################')\n",
    "    runKfold(train=train ,\n",
    "            train_targets=train_targets,\n",
    "            valid=valid ,\n",
    "            valid_targets=valid_targets ,\n",
    "            numberOfHiddenNodes=numberOfHiddenNodes,\n",
    "            activationFunction= 'sigmoid',\n",
    "            numberOfFolds = 3, \n",
    "            trainingCyclesPerValidation=5,\n",
    "            maxValidations = 1000,\n",
    "            maxLocalOptima = 15,\n",
    "            printConfusionMatrix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy scores lay in the same area as for the static train/test split, the mean scores being between approximately 80 and 90 per cent. The rankings between the different hidden node numbers differs somewhat from the static train/test split: the highest node number is still the best, but the lowest node number is now the worst. <br>\n",
    "\n",
    "The standard deviations gives extra information about the uncertainty of the different scores. We see that the standard deviations are so large for the two lowest node numebrs that the typical 95 per cent confidence intervals for normally distributed variables for the two lowest nodes overlaps. This also suggests that the rankings of the methods with the static method should be based on repetition of the simulations, as suggested earlier. <br>\n",
    "\n",
    "The highest node number case has almost no uncertainty. However, I other runs have given larger standard deviations also for this node number. <br>\n",
    "\n",
    "We conclude that the network performs about the same independent on whether static splitting or K-fold cross validation is used. Furthermore, the accuracy differences seem to be very uncertain, suggesting that the difference in quality between the chosen node numbers might not be that big."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
