{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES\n",
    "## 1.a \n",
    "__Question:__\n",
    "A common variant of evolution strategies used for (local) search is the (1 + 4) ES. How would this differ from the\n",
    "(1 + 1) ES in how the search space is explored? How does this, and(1 + $\\lambda$) in general, compared to hill climbing and greedy search? <br>\n",
    "\n",
    "__Answer:__\n",
    "($\\mu + \\lambda$) = (1 +4). Here we have 1 parent and 4 children. Since there is a \"+\", the 5 will compete for survival.  When ($\\mu + \\lambda$) = (1 +1), there is 1 parent and 1 child. The difference between (1 + 4) and (1 + 1), is that the possibility of the parent surviving decreases in (1+1). Put differently, the selection pressure is reduced in (1+1). With to regards to exploration of the search space, this increases with (1+4), since more solutions are compared.<br>\n",
    "\n",
    "(1 + $\\lambda$) vs. hill climbing: (1 + $\\lambda$) = hill climbing if $\\lambda = 1$, given that hill climbing only tests one neighbor.  <br>\n",
    "\n",
    "<mark>(1 + $\\lambda$) vs. greed search: With greedy one applies a rule and follows it to the end, while in (1 + $\\lambda$) <mark>.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b\n",
    "__Question:__\n",
    "What effect does an adaptive search strategy have on optimization performance? <br>\n",
    "\n",
    "__Answer:__\n",
    "An adaptive search algorithm changes parameters, e.g. mutation step size, based on how fast fitness is changing. See E&S p 101. In its simplest form children are generated by random numbers indepentent of the parents. The random numbers follows $N \\sim (0,\\sigma)$, where $\\sigma$ is the mutation step size, The mutation step size can change depending on the evolution of the problem. <br>\n",
    "\n",
    "A result of adaptive algorithms is that too early (trapped in local optima ) or late convergence can be avoided by adjustment of e.g. the mutation step size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c\n",
    "__Question:__ How would it affect the search if the strategy parameters were mutated after the solution parameters instead of before? <br>\n",
    "\n",
    "__Answer:__\n",
    "E&S p. 57 - 58. Strategy parameters should be mutated before the solution parameters. Reasoning is that the strategy should depend on the current situation and so affect the evolution to the next step. In this way new individuals are evaluated twice: first from the strategy and then from the solution mutation. Also, change in strategy has immediate effect on the new solution when strategy in mutated first.<br>\n",
    "<mark> UNCLEAR<br>\n",
    "    \n",
    "__Lonneke:__ <br>\n",
    "I do not understand what you mean by \"If the fitness does not change much for a given strategy parameter, the strategy parameter itself (e.g. mutation size) can be mutated.\"\n",
    "The fitness is only calculated based on the object variables. Two individuals with the exact same object variables, but completely different strategy parameters, have the same fitness score. The only difference between these two solutions is the rate in which they mutate/evolve. <br>\n",
    "\n",
    "\"Based on current fitness, the mutation step size is decided\" -> I do not think this is correct. <br>\n",
    "\n",
    "Imagine a genome as a list of variables. The first part of the list are the object variables, and the second part of the list are the strategy parameters. Object variables can be for example: the lengths of robot legs. Strategy parameters can be: the mutation rate, mutation step size.  The fitness of the robot (f. ex. how fast it can run) is directly dependent on the object variables. The rate at which this fitness evolves (fast evolution = fast change in the robot leg lengths, slow evolution = small change in the robot leg lengths) is directly dependent on the strategy parameters.<br>\n",
    "\n",
    "Let's say you just recombined two parents and have your potential child. Now you want to perform mutation. If you first mutate the strategy parameters (for example: I set the mutation rate to \"high\"), then it has direct effect on the object variables (the robot leg length is changed a lot), and thus an indirect effect on the new fitness value (remember the fitness value is ONLY calculated based on the object variables).<br>\n",
    "\n",
    "Now the other situation: you have recombined your parents, you have your potential child. First you mutate the object variables (based on the 'old' mutation rate that you still had from the previous round or initialization). Let's say the original mutation rate was \"low\", then your child doesn't mutate it's object variables much. Afterwards, you change the strategy parameters, for example switching the mutation rate from \"low\" to \"high\". This mutation rate however won't go into effect until the next round, after this solution has been recombined with a different one. So you will not directly in the current round see an effect of the \"high\" mutation rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a \n",
    "__Question:__ Ignoring mutation, and starting with the population {1,2,3,4} , implement and run 3 generations of a\n",
    "(4 + 8) ES maximizing $g(x) = x$, and observe what the end population looks like (use intermediary recombination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 3.0, 3.0, 3.0]\n",
      "[4.0, 3.0, 3.0, 3.0]\n",
      "[4.0, 4.0, 3.5, 3.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ES:\n",
    "    \n",
    "    def __init__(self, lambdaValue):\n",
    "        np.random.seed(1)\n",
    "\n",
    "        fitness = lambda x: x\n",
    "        crossover = lambda p1, p2: .5*(p1+p2)\n",
    "\n",
    "        numberOfGenerations = 3\n",
    "        numberOfParents = 4\n",
    "        numberOfChildren = lambdaValue\n",
    "\n",
    "        population = np.arange(1,4+1)\n",
    "\n",
    "        for generation in range(numberOfGenerations):\n",
    "            children = np.zeros(numberOfChildren)\n",
    "            for childNumber in range(numberOfChildren):\n",
    "                parent1Index = np.random.randint(numberOfParents) # Random selsection of parents\n",
    "                parent2Index = np.random.randint(numberOfParents)\n",
    "                children[childNumber] = crossover(parents[parent1Index], parents[parent2Index])\n",
    "            population = population, children\n",
    "            population = np.concatenate(population)\n",
    "            fitnessPopulation = (fitness(population))\n",
    "            population = [x for _,x in sorted(zip(fitnessPopulation, population))]  \n",
    "            population = population[::-1]\n",
    "            population = population[:4] # Keep only fittest individuals\n",
    "            print(population)\n",
    "\n",
    "numberOfChildren = 8\n",
    "es1 = ES(numberOfChildren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b\n",
    "__Question:__ If a (4, 8) ES had been used in Problem 2.a, what would the probability of the optimal solution (x = 4) surviving the first generation have been?<br>\n",
    "\n",
    "__Answer:__ With (4,8) the parents would have been deleted. The only way for 4 to stay, when using intermediary recombination, is if the parent with value 4 is mated with itself at least once. The probability of one child becoming 4 is $p_4 = 1/4 \\cdot 1/4 = 1/16$. The probability of at least one 4 among eight children is $1 - p_{Not 4} = 1 - (1 - p_4)^8 = 1 - (1 - 1/16)^8 = 1 - (15/16)^8  = 0.40328$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4032805261667818\n"
     ]
    }
   ],
   "source": [
    "print(1-(15./16)**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c\n",
    "__Question:__ Repeat Problem 2.a with an EP with q = 2. How do the two algorithms compare? <br>\n",
    "\n",
    "__Answer:__ I'll assume <mark>$q = \\lambda$.<mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 3.0, 3.0, 2.0]\n",
      "[4.0, 3.0, 3.0, 3.0]\n",
      "[4.0, 3.0, 3.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "numberOfChildren = 2\n",
    "es2 = ES(numberOfChildren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are 4 children instead of 8, there are fewer 4's left after three generations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "__Question:__ In a 0-1 knapsack problem, how could you implement a repair mutation to transform infeasible solutions into feasible ones (i.e. make the sum of costs of the selected items go below the budget)? <br>\n",
    "\n",
    "__Answer:__ Check surplus, remove item weight closest but at least as high as surplus. Or randomly throw out one item. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
